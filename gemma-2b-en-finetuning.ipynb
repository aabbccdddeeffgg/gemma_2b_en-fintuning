{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a2f200",
   "metadata": {
    "papermill": {
     "duration": 0.002958,
     "end_time": "2024-12-25T12:34:01.825722",
     "exception": false,
     "start_time": "2024-12-25T12:34:01.822764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Fintuning gemma_2b_en for simplified Chinese**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdcfce8",
   "metadata": {
    "papermill": {
     "duration": 0.002227,
     "end_time": "2024-12-25T12:34:01.830665",
     "exception": false,
     "start_time": "2024-12-25T12:34:01.828438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import neccessary package\n",
    "\n",
    "导入需要的库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c047364b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-25T12:34:01.836496Z",
     "iopub.status.busy": "2024-12-25T12:34:01.836199Z",
     "iopub.status.idle": "2024-12-25T12:37:26.976045Z",
     "shell.execute_reply": "2024-12-25T12:37:26.975175Z"
    },
    "papermill": {
     "duration": 205.145088,
     "end_time": "2024-12-25T12:37:26.978112",
     "exception": false,
     "start_time": "2024-12-25T12:34:01.833024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c7b05ae9.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/758dc0ed.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/eab6ca9b.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/6d94291a.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/3864cda3.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/47534735.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/88ec62ec.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/eb045dd1.json\" was modified by another program\r\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\r\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\r\n",
      "nodefaults/linux-64 (check zst) ━━━━━━━━━━━━━╸━━━━━━━━━━━   0.0 B Checking  0.1s\r\n",
      "nodefaults/noarch (check zst)   ━━━━━━━━━━━━━━╸━━━━━━━━━━   0.0 B Checking  0.1s\r\n",
      "nvidia/linux-64 (check zst)     -------------------------   0.0 B Checking  0.1s\r\n",
      "nvidia/noarch (check zst)       ━━━━━━━━━━━━━━╸━━━━━━━━━━   0.0 B Checking  0.1s\r\n",
      "rapidsai/linux-64 (check zst)   ━━━━━━━━━━━━╸━━━━━━━━━━━━   0.0 B Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\r\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch                                       ??.?MB @  ??.?MB/s  0.0s\r\n",
      "[+] 0.1s\r\n",
      "nodefaults/linux-64 \u001b[3m\u001b[5m\u001b[7m\u001b[9m\u001b[38;2;181;033;071m\u001b[48;2;213;013;212m-\u001b[0m\u001b[2m\u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[38;2;062;247;214m\u001b[48;2;044;058;028m----------------\u001b[0m\u001b[3m\u001b[5m\u001b[7m\u001b[9m\u001b[38;2;181;033;071m\u001b[48;2;213;013;212m-------\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "nodefaults/noarch   \u001b[1m\u001b[3m\u001b[4m\u001b[7m\u001b[8m\u001b[38;2;116;057;012m\u001b[48;2;098;032;101m--\u001b[0m\u001b[2m\u001b[5m\u001b[7m\u001b[8m\u001b[38;2;116;032;101m\u001b[48;2;105;106;111m----------------\u001b[0m\u001b[1m\u001b[3m\u001b[4m\u001b[7m\u001b[8m\u001b[38;2;116;057;012m\u001b[48;2;098;032;101m------\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "nvidia/linux-64     \u001b[136m\u001b[48;2;236;153;080m━╸\u001b[0m\u001b[04m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[136m\u001b[48;2;236;153;080m━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "rapidsai/linux-64   \u001b[1m\u001b[7m\u001b[38;2;175;220;051m\u001b[48;2;209;024;244m----\u001b[0m\u001b[5m\u001b[8m\u001b[9m\u001b[38;2;198;164;139m\u001b[48;2;147;181;164m----------------\u001b[0m\u001b[1m\u001b[7m\u001b[38;2;175;220;051m\u001b[48;2;209;024;244m----\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "rapidsai/noarch     \u001b[1m\u001b[2m\u001b[3m\u001b[4m\u001b[8m\u001b[9m\u001b[64m\u001b[48;2;168;211;000m━━╸\u001b[0m\u001b[1m\u001b[2m\u001b[5m\u001b[7m\u001b[8m\u001b[110m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[1m\u001b[2m\u001b[3m\u001b[4m\u001b[8m\u001b[9m\u001b[64m\u001b[48;2;168;211;000m━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/linux-64                                    197.8kB @ 626.0kB/s  0.1s\r\n",
      "rapidsai/noarch                                     ??.?MB @  ??.?MB/s  0.0s\r\n",
      "rapidsai/linux-64                                  397.5kB @ 648.7kB/s  0.1s\r\n",
      "nodefaults/linux-64                                 ??.?MB @  ??.?MB/s  0.1s\r\n",
      "nodefaults/noarch                                   ??.?MB @  ??.?MB/s  0.1s\r\n",
      "[+] 0.2s\r\n",
      "conda-forge/linux-64 \u001b[2m\u001b[4m\u001b[7m\u001b[8m\u001b[9m\u001b[38;2;000;092;180m\u001b[48;2;000;000;000m--------\u001b[0m\u001b[16m\u001b[48;2;034;140;224m---------------\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "conda-forge/noarch   \u001b[38;2;213;090;064m\u001b[48;2;213;081;064m-----------------------\u001b[0m 111.0kB /  18.0MB @   2.1MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m-\u001b[0m\u001b[16m\u001b[48;2;034;140;224m----------------------\u001b[0m   3.0MB /  40.9MB @  19.1MB/s  0.2s\r\n",
      "conda-forge/noarch   \u001b[38;2;212;104;144m\u001b[48;2;212;124;064m------\u001b[0m\u001b[38;2;213;090;064m\u001b[48;2;213;081;064m-----------------\u001b[0m   5.3MB /  18.0MB @  33.8MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m----\u001b[0m\u001b[16m\u001b[48;2;034;140;224m-------------------\u001b[0m   8.3MB /  40.9MB @  31.6MB/s  0.3s\r\n",
      "conda-forge/noarch   \u001b[38;2;212;104;144m\u001b[48;2;212;124;064m-------------\u001b[0m\u001b[38;2;213;090;064m\u001b[48;2;213;081;064m----------\u001b[0m  10.5MB /  18.0MB @  40.7MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m-------\u001b[0m\u001b[16m\u001b[48;2;034;140;224m----------------\u001b[0m  13.7MB /  40.9MB @  37.1MB/s  0.4s\r\n",
      "conda-forge/noarch   \u001b[38;2;212;104;144m\u001b[48;2;212;124;064m--------------------\u001b[0m\u001b[38;2;213;090;064m\u001b[48;2;213;081;064m---\u001b[0m  15.8MB /  18.0MB @  43.5MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m-------\u001b[0m\u001b[16m\u001b[48;2;034;140;224m----------------\u001b[0m  13.7MB /  40.9MB @  37.1MB/s  0.5s\r\n",
      "conda-forge/noarch   \u001b[38;2;212;104;144m\u001b[48;2;212;124;064m--------------------\u001b[0m\u001b[38;2;213;090;064m\u001b[48;2;213;081;064m---\u001b[0m  15.8MB /  18.0MB @  43.5MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  18.0MB @  43.5MB/s  0.5s\r\n",
      "[+] 0.7s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m-----------\u001b[0m\u001b[16m\u001b[48;2;034;140;224m------------\u001b[0m  20.8MB /  40.9MB @  36.7MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m-----------------\u001b[0m\u001b[16m\u001b[48;2;034;140;224m------\u001b[0m  30.5MB /  40.9MB @  45.7MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m----------------------\u001b[0m\u001b[16m\u001b[48;2;034;140;224m-\u001b[0m  40.4MB /  40.9MB @  52.6MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m----------------------\u001b[0m\u001b[16m\u001b[48;2;034;140;224m-\u001b[0m  40.4MB /  40.9MB @  52.6MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\r\n",
      "conda-forge/linux-64 \u001b[38;2;034;140;224m\u001b[48;2;163;038;064m----------------------\u001b[0m\u001b[16m\u001b[48;2;034;140;224m-\u001b[0m  40.4MB /  40.9MB @  52.6MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                40.9MB @  52.6MB/s  1.1s\r\n",
      "[+] 1.2s\r\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\r\n",
      "\r\n",
      "Transaction\r\n",
      "\r\n",
      "  Prefix: /opt/conda/envs/myenv\r\n",
      "\r\n",
      "  Updating specs:\r\n",
      "\r\n",
      "   - python=3.9\r\n",
      "\r\n",
      "\r\n",
      "  Package                Version  Build               Channel           Size\r\n",
      "──────────────────────────────────────────────────────────────────────────────\r\n",
      "  Install:\r\n",
      "──────────────────────────────────────────────────────────────────────────────\r\n",
      "\r\n",
      "  \u001b[32m+ _libgcc_mutex   \u001b[0m         0.1  conda_forge         conda-forge        3kB\r\n",
      "  \u001b[32m+ _openmp_mutex   \u001b[0m         4.5  2_gnu               conda-forge       24kB\r\n",
      "  \u001b[32m+ bzip2           \u001b[0m       1.0.8  h4bc722e_7          conda-forge      253kB\r\n",
      "  \u001b[32m+ ca-certificates \u001b[0m  2024.12.14  hbcca054_0          conda-forge      157kB\r\n",
      "  \u001b[32m+ ld_impl_linux-64\u001b[0m        2.43  h712a8e2_2          conda-forge      669kB\r\n",
      "  \u001b[32m+ libffi          \u001b[0m       3.4.2  h7f98852_5          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libgcc          \u001b[0m      14.2.0  h77fa898_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libgcc-ng       \u001b[0m      14.2.0  h69a702a_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libgomp         \u001b[0m      14.2.0  h77fa898_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ liblzma         \u001b[0m       5.6.3  hb9d3cd8_1          conda-forge      111kB\r\n",
      "  \u001b[32m+ libnsl          \u001b[0m       2.0.1  hd590300_0          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libsqlite       \u001b[0m      3.47.2  hee588c1_0          conda-forge      874kB\r\n",
      "  \u001b[32m+ libuuid         \u001b[0m      2.38.1  h0b41bf4_0          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libxcrypt       \u001b[0m      4.4.36  hd590300_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libzlib         \u001b[0m       1.3.1  hb9d3cd8_2          conda-forge       61kB\r\n",
      "  \u001b[32m+ ncurses         \u001b[0m         6.5  he02047a_1          conda-forge      889kB\r\n",
      "  \u001b[32m+ openssl         \u001b[0m       3.4.0  hb9d3cd8_0          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ pip             \u001b[0m      24.3.1  pyh8b19718_2        conda-forge        1MB\r\n",
      "  \u001b[32m+ python          \u001b[0m      3.9.21  h9c0c6dc_1_cpython  conda-forge       24MB\r\n",
      "  \u001b[32m+ readline        \u001b[0m         8.2  h8228510_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ setuptools      \u001b[0m      75.6.0  pyhff2d567_1        conda-forge      774kB\r\n",
      "  \u001b[32m+ tk              \u001b[0m      8.6.13  noxft_h4845f30_101  conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ tzdata          \u001b[0m       2024b  hc8b5060_0          conda-forge      122kB\r\n",
      "  \u001b[32m+ wheel           \u001b[0m      0.45.1  pyhd8ed1ab_1        conda-forge       63kB\r\n",
      "\r\n",
      "  Summary:\r\n",
      "\r\n",
      "  Install: 24 packages\r\n",
      "\r\n",
      "  Total download: 29MB\r\n",
      "\r\n",
      "──────────────────────────────────────────────────────────────────────────────\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Transaction starting\r\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\r\n",
      "Downloading      ╸\u001b[5m\u001b[9m\u001b[38;2;000;000;000m\u001b[48;2;000;000;000m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B                            0.0s\r\n",
      "Extracting       \u001b[93m\u001b[48;2;220;201;160m-----------------------\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\r\n",
      "Downloading  (5) \u001b[5m\u001b[9m\u001b[38;2;000;000;000m\u001b[48;2;000;000;000m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B libsqlite                  0.0s\r\n",
      "Extracting       \u001b[93m\u001b[48;2;220;201;160m-----------------------\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gncurses                                            889.1kB @   3.3MB/s  0.1s\r\n",
      "setuptools                                         774.3kB @ 649.5kB/s  0.1s\r\n",
      "libsqlite                                          873.6kB @ 627.2kB/s  0.1s\r\n",
      "pip                                                  1.2MB @ 658.0kB/s  0.1s\r\n",
      "ld_impl_linux-64                                   669.2kB @  ??.?MB/s  0.0s\r\n",
      "bzip2                                              252.8kB @  ??.?MB/s  0.0s\r\n",
      "ca-certificates                                    157.1kB @  ??.?MB/s  0.0s\r\n",
      "tzdata                                             122.4kB @  ??.?MB/s  0.1s\r\n",
      "[+] 0.2s\r\n",
      "Downloading  (5) ━━━━━━━━━━╸\u001b[5m\u001b[9m\u001b[38;2;000;000;000m\u001b[48;2;000;000;000m━━━━━━━━━━━━\u001b[0m  14.6MB _openmp_mutex              0.1s\r\n",
      "Extracting   (8) \u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[00m\u001b[10m---------\u001b[0m\u001b[93m\u001b[48;2;220;201;160m--------------\u001b[0m       0 bzip2                      0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gliblzma                                            111.1kB @  ??.?MB/s  0.0s\r\n",
      "wheel                                               62.9kB @  ??.?MB/s  0.0s\r\n",
      "libzlib                                             61.0kB @  ??.?MB/s  0.0s\r\n",
      "_openmp_mutex                                       23.6kB @  ??.?MB/s  0.0s\r\n",
      "_libgcc_mutex                                        2.6kB @  ??.?MB/s  0.0s\r\n",
      "python                                              23.6MB @  78.4MB/s  0.2s\r\n",
      "[+] 0.3s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  28.9MB                            0.2s\r\n",
      "Extracting  (11) ---\u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[00m\u001b[10m-------------------\u001b[0m\u001b[93m\u001b[48;2;220;201;160m-\u001b[0m       2 bzip2                      0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  28.9MB                            0.2s\r\n",
      "Extracting   (4) --------------\u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[00m\u001b[10m--------\u001b[0m\u001b[93m\u001b[48;2;220;201;160m-\u001b[0m       9 bzip2                      0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  28.9MB                            0.2s\r\n",
      "Extracting   (3) ------------------\u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[00m\u001b[10m-----\u001b[0m      11 ncurses                    0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  28.9MB                            0.2s\r\n",
      "Extracting   (1) ---------------------\u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[00m\u001b[10m--\u001b[0m      13 python                     0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  28.9MB                            0.2s\r\n",
      "Extracting   (1) ---------------------\u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[00m\u001b[10m--\u001b[0m      13 python                     0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  28.9MB                            0.2s\r\n",
      "Extracting   (1) ---------------------\u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[00m\u001b[10m--\u001b[0m      13 python                     0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  28.9MB                            0.2s\r\n",
      "Extracting   (1) ---------------------\u001b[3m\u001b[4m\u001b[5m\u001b[8m\u001b[9m\u001b[00m\u001b[10m--\u001b[0m      13 python                     0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hLinking _libgcc_mutex-0.1-conda_forge\r\n",
      "Linking ld_impl_linux-64-2.43-h712a8e2_2\r\n",
      "Linking ca-certificates-2024.12.14-hbcca054_0\r\n",
      "Linking libgomp-14.2.0-h77fa898_1\r\n",
      "Linking _openmp_mutex-4.5-2_gnu\r\n",
      "Linking libgcc-14.2.0-h77fa898_1\r\n",
      "Linking libzlib-1.3.1-hb9d3cd8_2\r\n",
      "Linking liblzma-5.6.3-hb9d3cd8_1\r\n",
      "Linking libgcc-ng-14.2.0-h69a702a_1\r\n",
      "Linking openssl-3.4.0-hb9d3cd8_0\r\n",
      "Linking libsqlite-3.47.2-hee588c1_0\r\n",
      "Linking libffi-3.4.2-h7f98852_5\r\n",
      "Linking tk-8.6.13-noxft_h4845f30_101\r\n",
      "Linking libxcrypt-4.4.36-hd590300_1\r\n",
      "Linking bzip2-1.0.8-h4bc722e_7\r\n",
      "Linking ncurses-6.5-he02047a_1\r\n",
      "Linking libuuid-2.38.1-h0b41bf4_0\r\n",
      "Linking libnsl-2.0.1-hd590300_0\r\n",
      "Linking readline-8.2-h8228510_1\r\n",
      "Linking tzdata-2024b-hc8b5060_0\r\n",
      "Linking python-3.9.21-h9c0c6dc_1_cpython\r\n",
      "Linking wheel-0.45.1-pyhd8ed1ab_1\r\n",
      "Linking setuptools-75.6.0-pyhff2d567_1\r\n",
      "Linking pip-24.3.1-pyh8b19718_2\r\n",
      "\r\n",
      "Transaction finished\r\n",
      "\r\n",
      "To activate this environment, use:\r\n",
      "\r\n",
      "    conda activate myenv\r\n",
      "\r\n",
      "Or to execute a single command in this environment, use:\r\n",
      "\r\n",
      "    conda run -n myenv mycommand\r\n",
      "\r\n",
      "Your parent process name is Name:\tpython.\r\n",
      "If your shell is xonsh, please use \"-s xonsh\".\r\n",
      "\r\n",
      "'conda' is running as a subprocess and can't modify the parent shell.\r\n",
      "Thus you must initialize your shell before using activate and deactivate.\r\n",
      "\r\n",
      "To initialize the current  shell, run:\r\n",
      "    $ eval \"$(conda shell hook --shell )\"\r\n",
      "and then activate or deactivate with:\r\n",
      "    $ conda activate\r\n",
      "To automatically initialize all future () shells, run:\r\n",
      "    $ conda shell init --shell  --root-prefix=~/.local/share/mamba\r\n",
      "If your shell was already initialized, reinitialize your shell with:\r\n",
      "    $ conda shell reinit --shell \r\n",
      "Otherwise, this may be an issue. In the meantime you can run commands. See:\r\n",
      "    $ conda run --help\r\n",
      "\r\n",
      "Supported shells are {bash, zsh, csh, posix, xonsh, cmd.exe, powershell, fish, nu}.\r\n",
      "\u001b[1m\u001b[41mcritical libmamba\u001b[m Shell not initialized\r\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /opt/conda/lib/python3.10/site-packages (2.16.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.62.2)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.3.3)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.37.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.26.4)\r\n",
      "Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.3.101 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.43.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (0.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2024.6.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (3.1.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow[and-cuda]) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (2.1.5)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow[and-cuda]) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow[and-cuda]) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow[and-cuda]) (0.1.2)\r\n",
      "Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (412.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.6/412.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (14.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (22.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (24.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (867 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl (98.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl (125.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl (197.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.5/197.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "Successfully installed nvidia-cublas-cu12-12.3.4.1 nvidia-cuda-cupti-cu12-12.3.101 nvidia-cuda-nvcc-cu12-12.3.107 nvidia-cuda-nvrtc-cu12-12.3.107 nvidia-cuda-runtime-cu12-12.3.101 nvidia-cudnn-cu12-8.9.7.29 nvidia-cufft-cu12-11.0.12.1 nvidia-curand-cu12-10.3.4.107 nvidia-cusolver-cu12-11.5.4.101 nvidia-cusparse-cu12-12.2.0.103 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\r\n",
      "Collecting keras\r\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.11.0)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.3.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.12.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras) (3.1.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n",
      "Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: keras\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "Successfully installed keras-3.7.0\r\n",
      "Requirement already satisfied: keras-nlp in /opt/conda/lib/python3.10/site-packages (0.17.0)\r\n",
      "Collecting keras-nlp\r\n",
      "  Downloading keras_nlp-0.18.1-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting keras-hub==0.18.1 (from keras-nlp)\r\n",
      "  Downloading keras_hub-0.18.1-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (21.3)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (2024.5.15)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (13.7.1)\r\n",
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (0.3.4)\r\n",
      "Requirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (2.16.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (4.66.4)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-hub==0.18.1->keras-nlp) (3.1.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.18.1->keras-nlp) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.18.1->keras-nlp) (2.18.0)\r\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.16.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.18.1->keras-nlp) (0.1.2)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.3.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.62.2)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.7.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.37.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (2024.6.2)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.43.0)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.11.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.1.5)\r\n",
      "Downloading keras_nlp-0.18.1-py3-none-any.whl (2.0 kB)\r\n",
      "Downloading keras_hub-0.18.1-py3-none-any.whl (691 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.2/691.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: keras-hub, keras-nlp\r\n",
      "  Attempting uninstall: keras-hub\r\n",
      "    Found existing installation: keras-hub 0.17.0\r\n",
      "    Uninstalling keras-hub-0.17.0:\r\n",
      "      Successfully uninstalled keras-hub-0.17.0\r\n",
      "  Attempting uninstall: keras-nlp\r\n",
      "    Found existing installation: keras-nlp 0.17.0\r\n",
      "    Uninstalling keras-nlp-0.17.0:\r\n",
      "      Successfully uninstalled keras-nlp-0.17.0\r\n",
      "Successfully installed keras-hub-0.18.1 keras-nlp-0.18.1\r\n",
      "Collecting tensorrt\r\n",
      "  Downloading tensorrt-10.7.0.tar.gz (16 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting tensorrt_cu12==10.7.0 (from tensorrt)\r\n",
      "  Downloading tensorrt_cu12-10.7.0.tar.gz (18 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu12\r\n",
      "  Building wheel for tensorrt (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for tensorrt: filename=tensorrt-10.7.0-py2.py3-none-any.whl size=16337 sha256=761b19b63388bcc231402d093ae7d8783e5b275a9a61f81f644b432eb1a046b1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/da/cb/16/d5add64df498ec418cc9eb2885dc828a67a002afc30873d932\r\n",
      "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.7.0-py2.py3-none-any.whl size=17550 sha256=2485439dd1c1883abb8300790dc7626d921df449f69d33eebcf5c40712315c7e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/dd/9d/413a390ab4b9ebf16701f91cecf9d94a2d481ea2949bcd72e9\r\n",
      "Successfully built tensorrt tensorrt_cu12\r\n",
      "Installing collected packages: tensorrt_cu12, tensorrt\r\n",
      "Successfully installed tensorrt-10.7.0 tensorrt_cu12-10.7.0\r\n"
     ]
    }
   ],
   "source": [
    "!conda create -n myenv python=3.9 -y\n",
    "!conda activate myenv\n",
    "!pip install \"tensorflow[and-cuda]\"\n",
    "!pip install -U keras\n",
    "!pip install -U keras-nlp\n",
    "!pip install tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7740c",
   "metadata": {
    "papermill": {
     "duration": 0.035207,
     "end_time": "2024-12-25T12:37:27.049984",
     "exception": false,
     "start_time": "2024-12-25T12:37:27.014777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import metric using rouge \n",
    "\n",
    "导入评估所需库使用rouge指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94f2e95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-25T12:37:27.122831Z",
     "iopub.status.busy": "2024-12-25T12:37:27.122516Z",
     "iopub.status.idle": "2024-12-25T12:37:45.555766Z",
     "shell.execute_reply": "2024-12-25T12:37:45.554912Z"
    },
    "papermill": {
     "duration": 18.472341,
     "end_time": "2024-12-25T12:37:45.557704",
     "exception": false,
     "start_time": "2024-12-25T12:37:27.085363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\r\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\r\n",
      "Building wheels for collected packages: rouge-score\r\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=9e7e7c9d8df2e7e7711c6e17b2549fbb84e580e1e26ce5ae24018934cff35dae\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\r\n",
      "Successfully built rouge-score\r\n",
      "Installing collected packages: rouge-score\r\n",
      "Successfully installed rouge-score-0.1.2\r\n",
      "Collecting rouge-chinese\r\n",
      "  Downloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge-chinese) (1.16.0)\r\n",
      "Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\r\n",
      "Installing collected packages: rouge-chinese\r\n",
      "Successfully installed rouge-chinese-1.0.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score\n",
    "!pip install rouge-chinese"
   ]
  },
  {
   "attachments": {
    "bdd47968-dc56-45cb-acd1-dc2653617bc8.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5101464e",
   "metadata": {
    "papermill": {
     "duration": 0.036001,
     "end_time": "2024-12-25T12:37:45.631131",
     "exception": false,
     "start_time": "2024-12-25T12:37:45.595130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code is evaluated using rouge metrics, including rouge1 and rougeL metrics.\n",
    "\n",
    "**ROUGE-1 (Rouge-1)**\n",
    "\n",
    "ROUGE-1 is a special case of ROUGE-N, focusing on the recall rate of 1-gram (single word). It calculates the ratio of the number of 1-grams shared between the automatically generated abstracts (candidate abstracts) and the reference abstracts to the total number of 1-grams in the reference abstracts. To be specific:\n",
    "\n",
    "* Molecule: The number of 1-grams that appear in both candidate abstracts and reference abstracts.\n",
    "* Denominator: The number of 1-grams of the reference summary. The formula for calculating ROUGE-1 can be expressed as: ROUGE-1 = Count Match/Reference Count\n",
    "\n",
    "Where, Count Match is the maximum number of 1-grams shared by the candidate digest and the Reference digest, and Reference Count is the total number of 1-grams in the reference digest. ROUGE-1 intuitively and concisely reflects word order, and is suitable for short summary evaluation and multi-document summary (without stopping word conditions).\n",
    "\n",
    "**ROUGE-L (Rouge-L)**\n",
    "\n",
    "ROUGE-L is an evaluation metric based on the Longest Common Subsequence (LCS). It calculates the length of the longest common subsequence between the automatically generated summary and the reference summary and measures the similarity between the two. To be specific:\n",
    "\n",
    "* LCS(X, Y) : The length of the longest common subsequence of X and Y.\n",
    "* m, n: indicates the length of the reference summary and the automatic summary, respectively (generally the number of words included).\n",
    "* Rlcs, Plcs: Recall rate and accuracy, respectively.\n",
    "* Flcs: ROUGE-L is an F-measure of recall rate and accuracy.\n",
    "\n",
    "* The calculation formula of ROUGE-L can be expressed as:![微信截图_20241224120237.png](attachment:bdd47968-dc56-45cb-acd1-dc2653617bc8.png)\n",
    "\n",
    "Among them, beta is a parameter used to balance recall rates and accuracy, usually set to a larger number, so that ROUGE-L considers almost only recall rates. This is in contrast to the general evaluation method that only considers the recall rate.\n",
    "\n",
    "评估代码，使用的是rouge指标，包括rouge1和rougeL指标。\n",
    "\n",
    "**ROUGE-1 (Rouge-1)**\n",
    "\n",
    "ROUGE-1是ROUGE-N的一个特例，专注于1-gram（单个词）的召回率。它计算的是自动生成的摘要（候选摘要）与参考摘要之间共有的1-gram的数量与参考摘要中1-gram总数的比例。具体来说：\n",
    "\n",
    "* 分子：候选摘要和参考摘要都出现的1-gram的个数。\n",
    "* 分母：参考摘要的1-gram个数。ROUGE-1的计算公式可以表示为：ROUGE-1 = Count Match / Reference Count\n",
    "\n",
    "其中，Count Match是候选摘要和参考摘要共有的1-gram的最大数量，Reference Count是参考摘要中1-gram的总数量。ROUGE-1能够直观、简洁地反映词序，适用于短摘要评估和多文档摘要（去停用词条件）。\n",
    "\n",
    "**ROUGE-L (Rouge-L)**\n",
    "\n",
    "ROUGE-L是基于最长公共子序列（Longest Common Subsequence, LCS）的评估指标。它计算自动生成的摘要与参考摘要之间的最长公共子序列的长度，并以此来衡量两者的相似度。具体来说：\n",
    "\n",
    "* LCS(X, Y)：X和Y的最长公共子序列的长度。\n",
    "* m, n：分别表示参考摘要和自动摘要的长度（一般就是所含词的个数）。\n",
    "* Rlcs, Plcs：分别表示召回率和准确率。\n",
    "* Flcs：即ROUGE-L，是召回率和准确率的F-measure。\n",
    "  \n",
    "* ROUGE-L的计算公式可以表示为：![微信截图_20241224120237.png](attachment:bdd47968-dc56-45cb-acd1-dc2653617bc8.png)\n",
    "\n",
    "其中，β是一个用于平衡召回率和准确率的参数，通常设置为一个较大的数，使得ROUGE-L几乎只考虑召回率。这与一般只考虑召回率的评估方法相对应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f19d688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-25T12:37:45.705621Z",
     "iopub.status.busy": "2024-12-25T12:37:45.705298Z",
     "iopub.status.idle": "2024-12-25T12:37:45.959632Z",
     "shell.execute_reply": "2024-12-25T12:37:45.958976Z"
    },
    "papermill": {
     "duration": 0.293784,
     "end_time": "2024-12-25T12:37:45.961533",
     "exception": false,
     "start_time": "2024-12-25T12:37:45.667749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rouge_chinese import Rouge\n",
    "import jieba\n",
    "\n",
    "def evaluate_with_rouge(reference_list, generated_list):\n",
    "    # 创建ROUGE对象\n",
    "    rouge = Rouge()\n",
    "\n",
    "    # 存储ROUGE评分的列表\n",
    "    rouge1_scores = []\n",
    "    rougeL_scores = []\n",
    "\n",
    "    # 遍历每一对字符串，计算ROUGE评分\n",
    "    for reference, generated in zip(reference_list, generated_list):\n",
    "        reference = ' '.join(jieba.cut(reference))\n",
    "        generated = ' '.join(jieba.cut(generated))\n",
    "        scores = rouge.get_scores(reference, generated)\n",
    "        # 将每个ROUGE评分的F1值添加到列表中\n",
    "        rouge1_scores.append(scores[0]['rouge-1'][\"f\"])\n",
    "        rougeL_scores.append(scores[0]['rouge-l'][\"f\"])\n",
    "\n",
    "    # 计算ROUGE-1和ROUGE-L的平均F1值\n",
    "    avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores) if rouge1_scores else 0\n",
    "    avg_rougeL = sum(rougeL_scores) / len(rougeL_scores) if rougeL_scores else 0\n",
    "\n",
    "    # 返回平均分数\n",
    "    return avg_rouge1, avg_rougeL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07def5f3",
   "metadata": {
    "papermill": {
     "duration": 0.035856,
     "end_time": "2024-12-25T12:37:46.034308",
     "exception": false,
     "start_time": "2024-12-25T12:37:45.998452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The fine-tuned data includes data related to Chinese history, geography, and literature, with particular attention to the reading comprehension of literature, the understanding of Chinese culture, and the generated content of Chinese literature, which is derived from the generated data of ChatGPT.\n",
    "\n",
    "微调的数据中包含中国的历史、地理、文学相关的数据，尤其关注了文学的阅读理解、中国文化理解以及中国文学生成内容，来源于ChatGPT的生成数据。\n",
    "\n",
    "Our fine-tuning technology uses lora low-rank adaptation, which makes the fine-tuning speed faster, and the fine-tuning code is as follows:\n",
    "\n",
    "我们的微调技术使用的是lora低秩适应，使得微调速度加快，微调的代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24a7a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-25T12:37:46.108654Z",
     "iopub.status.busy": "2024-12-25T12:37:46.108316Z",
     "iopub.status.idle": "2024-12-25T12:57:01.906279Z",
     "shell.execute_reply": "2024-12-25T12:57:01.905309Z"
    },
    "papermill": {
     "duration": 1155.941123,
     "end_time": "2024-12-25T12:57:02.012191",
     "exception": false,
     "start_time": "2024-12-25T12:37:46.071068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fine-tuning:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735130335.233263      23 service.cc:145] XLA service 0x5c769966ce80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735130335.233311      23 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1735130342.979107      23 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference answer:\n",
      "静夜思\n",
      "generate data:\n",
      "问题:\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "回答:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，\n",
      "reference answer:\n",
      "文章主要描述了滁州西南的醉翁亭及其周围的自然风光，表达了作者与民同乐的情怀。\n",
      "generate data:\n",
      "问题:\n",
      "根据以下古文，概括其主要内容：文言文标题: 醉翁亭记 作者: 欧阳修 正文: 环滁皆山也。\n",
      "\n",
      "回答:\n",
      "1. 醉翁亭记是古文，是古诗。\n",
      "2. 醉翁亭记是古诗，是古文。\n",
      "3. 醉翁亭记是古文，是古诗。\n",
      "4. 醉翁亭记是古诗，是古文。\n",
      "5. 醉翁亭记是古诗，是古文。\n",
      "6. 醉翁亭记是古文，是古诗。\n",
      "7. 醉翁亭记是古诗，是古文。\n",
      "8. 醉翁亭记是古文，是古诗。\n",
      "9. 醉翁亭记是古诗，是古文。\n",
      "10. 醉翁亭记是古文，是古诗。\n",
      "11. 醉翁亭记是古诗，是古文。\n",
      "12. 醉翁亭记是古文，是古诗。\n",
      "13. 醉翁亭记是古诗，是古文。\n",
      "14. 醉翁亭记是古文，是古诗。\n",
      "15. 醉翁亭记是古诗，是古文。\n",
      "16. 醉翁亭记是古文，是古诗。\n",
      "17. 醉翁亭记是古诗，是古文。\n",
      "18. 醉翁亭记是古文，是古诗。\n",
      "19. 醉翁亭记是古诗，是古文。\n",
      "20. 醉翁亭记是古文，是古诗。\n",
      "21. 醉翁亭记是古诗，是古文。\n",
      "22. 醉翁亭记是古文，是古诗。\n",
      "23. 醉翁亭记是古诗，是古文。\n",
      "24. 醉翁亭记是古文，是古诗。\n",
      "25. 醉翁亭记是古诗，是古文。\n",
      "26. 醉翁亭记是古文，是古诗。\n",
      "27. 醉翁亭记是古诗，是古文。\n",
      "28. 醉翁亭记是古文，是古诗。\n",
      "29\n",
      "reference answer:\n",
      "这首词用词极为叠沓，强调了作者内心的孤独与悲痛，充分表现了情感的深沉与无助。\n",
      "generate data:\n",
      "问题:\n",
      "阅读以下宋词，并分析其用词特点：词牌名: 声声慢 作者: 李清照 正文: 寻寻觅觅，冷冷清清，凄凄惨惨戚戚。\n",
      "\n",
      "回答:\n",
      "1.词牌名: 声声慢\n",
      "2.词牌名: 觅觅\n",
      "3.词牌名: 戚戚\n",
      "4.词牌名: 惨惨\n",
      "5.词牌名: 凄凄\n",
      "6.词牌名: 觅觅\n",
      "7.词牌名: 戚戚\n",
      "8.词牌名: 惨惨\n",
      "9.词牌名: 凄凄\n",
      "10.词牌名: 觅觅\n",
      "11.词牌名: 戚戚\n",
      "12.词牌名: 惨惨\n",
      "13.词牌名: 凄凄\n",
      "14.词牌名: 觅觅\n",
      "15.词牌名: 戚戚\n",
      "16.词牌名: 惨惨\n",
      "17.词牌名: 凄凄\n",
      "18.词牌名: 觅觅\n",
      "19.词牌名: 戚戚\n",
      "20.词牌名: 惨惨\n",
      "21.词牌名: 凄凄\n",
      "22.词牌名: 觅觅\n",
      "23.词牌名: 戚戚\n",
      "24.词牌名: 惨惨\n",
      "25.词牌名: 凄凄\n",
      "26.词牌名: 觅觅\n",
      "27.词牌名: 戚戚\n",
      "28.词牌名: 惨惨\n",
      "29.词牌名: 凄凄\n",
      "30.词牌名: 觅觅\n",
      "31.词牌名: 戚戚\n",
      "32.词牌名: 惨惨\n",
      "33.词牌名: 凄凄\n",
      "34.词牌名: 觅觅\n",
      "35.词牌名: 戚戚\n",
      "36.词牌名: 惨惨\n",
      "37.词牌名: 凄凄\n",
      "38.词牌名: 觅觅\n",
      "39.词牌名: 戚戚\n",
      "40.词牌名: 惨惨\n",
      "41.词牌名: 凄凄\n",
      "42.词牌名: 觅觅\n",
      "43.词牌名:\n",
      "reference answer:\n",
      "山间溪流潺潺，桃花片片随风飘落，点缀在青翠的草地上。四周群山环绕，鸟鸣声声，宛若世外桃源。远处竹林深深，似有炊烟袅袅升起，一切宁静而美好。\n",
      "generate data:\n",
      "问题:\n",
      "根据题目‘桃花源记’，写一段描写桃花源景色的文字。\n",
      "\n",
      "回答:\n",
      "桃花源记是鲁迅的代表作之一，描写了鲁迅的童年，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年\n",
      "reference answer:\n",
      "渔舟摇夕影，歌起晚风轻。\n",
      "水色天光共，归途满笛声。\n",
      "generate data:\n",
      "问题:\n",
      "以‘渔舟唱晚’为主题，创作一首五言绝句。\n",
      "\n",
      "回答:\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔\n",
      "reference answer:\n",
      "老街的记忆，是那些斑驳的墙面，是那些回响在小巷中的笑声，是那些岁月带不走的温暖。\n",
      "generate data:\n",
      "问题:\n",
      "以‘老街的记忆’为题，创作一段怀旧风格的散文。\n",
      "\n",
      "回答:\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老\n",
      "reference answer:\n",
      "丝绸之路是连接中西方的重要贸易通道，促进了文化交流与经济繁荣。\n",
      "generate data:\n",
      "问题:\n",
      "简述‘丝绸之路’在古代贸易中的作用。\n",
      "\n",
      "回答:\n",
      "丝绸之路是古代丝绸贸易的通道，是丝绸贸易的“丝路”。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.679 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1: 0.1741\n",
      "Rouge-L: 0.0230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1735130731.391194     207 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735130742.180951     207 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_9', 436 bytes spill stores, 508 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_6', 436 bytes spill stores, 508 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 369ms/step - loss: 0.4930 - sparse_categorical_accuracy: 0.4713\n",
      "Lora weights saved.\n",
      "After fine-tuning:\n",
      "\n",
      "reference answer:\n",
      "静夜思\n",
      "generate data:\n",
      "问题:\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "回答:\n",
      "《雪中悍刀行》\n",
      "reference answer:\n",
      "文章主要描述了滁州西南的醉翁亭及其周围的自然风光，表达了作者与民同乐的情怀。\n",
      "generate data:\n",
      "问题:\n",
      "根据以下古文，概括其主要内容：文言文标题: 醉翁亭记 作者: 欧阳修 正文: 环滁皆山也。\n",
      "\n",
      "回答:\n",
      "醉翁亭记，作者欧阳修，描写了作者在环滁山上的游玩。\n",
      "reference answer:\n",
      "这首词用词极为叠沓，强调了作者内心的孤独与悲痛，充分表现了情感的深沉与无助。\n",
      "generate data:\n",
      "问题:\n",
      "阅读以下宋词，并分析其用词特点：词牌名: 声声慢 作者: 李清照 正文: 寻寻觅觅，冷冷清清，凄凄惨惨戚戚。\n",
      "\n",
      "回答:\n",
      "这首词描绘了李清照在 snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white snow-white\n",
      "reference answer:\n",
      "山间溪流潺潺，桃花片片随风飘落，点缀在青翠的草地上。四周群山环绕，鸟鸣声声，宛若世外桃源。远处竹林深深，似有炊烟袅袅升起，一切宁静而美好。\n",
      "generate data:\n",
      "问题:\n",
      "根据题目‘桃花源记’，写一段描写桃花源景色的文字。\n",
      "\n",
      "回答:\n",
      "桃花源是清华山的一处名胜，其景色优美，水清山高，风光秀丽。\n",
      "reference answer:\n",
      "渔舟摇夕影，歌起晚风轻。\n",
      "水色天光共，归途满笛声。\n",
      "generate data:\n",
      "问题:\n",
      "以‘渔舟唱晚’为主题，创作一首五言绝句。\n",
      "\n",
      "回答:\n",
      "渔舟唱晚，渔民歌唱。渔舟唱晚，渔民歌唱。渔舟唱晚，渔民歌唱。渔舟唱晚，渔民歌唱。\n",
      "reference answer:\n",
      "老街的记忆，是那些斑驳的墙面，是那些回响在小巷中的笑声，是那些岁月带不走的温暖。\n",
      "generate data:\n",
      "问题:\n",
      "以‘老街的记忆’为题，创作一段怀旧风格的散文。\n",
      "\n",
      "回答:\n",
      "老街的记忆，是时光的流逝，是岁月留下的痕迹。它是一座古老的街，有着许多历史的记忆，也是许多人的回忆。它是一座古老的街，有着许多历史的记忆，也是许多人的回忆。它是一座古老的街，有着许多历史的记忆，也是许多人的回忆。\n",
      "reference answer:\n",
      "丝绸之路是连接中西方的重要贸易通道，促进了文化交流与经济繁荣。\n",
      "generate data:\n",
      "问题:\n",
      "简述‘丝绸之路’在古代贸易中的作用。\n",
      "\n",
      "回答:\n",
      "丝绸之路是古代世界贸易的重要通道， connecting Asia and Europe， connecting East and West， connecting the past and the future.\n",
      "After fine-tuning:\n",
      "Rouge-1: 0.2607\n",
      "Rouge-L: 0.1940\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import keras\n",
    "import keras_nlp\n",
    "import re\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"wyq1234597\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"b3439dbc7b41a30c50a40b6b44613c06\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n",
    "\n",
    "template = \"问题:\\n{instruction}\\n\\n回答:\\n{response}\"\n",
    "\n",
    "# 加载训练集(json)格式(问答)\n",
    "train_data = []\n",
    "with open(\"/kaggle/input/data-of-wyq1234/zh_seed_tasks.jsonl\") as tarin_file:\n",
    "    for line in tarin_file:\n",
    "        line = line.strip()  # 去掉首尾空白符\n",
    "        if not line:  # 跳过空行\n",
    "            continue\n",
    "        try:\n",
    "            features = json.loads(line)\n",
    "            # template_qa = \"问题:\\n{instruction}\\n\\n回答:\\n{response}\"\n",
    "            instruction = features[\"instruction\"]\n",
    "            response = features[\"response\"]\n",
    "            train_data.append(template.format(instruction=instruction, response=response))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"跳过格式错误的行: {line} 错误: {e}\")\n",
    "\n",
    "# 加载测试集(json)，分别存为指令以及响应\n",
    "test_data_instruction = []\n",
    "test_data_response = []\n",
    "with open(\"/kaggle/input/data-of-wyq1234/test.jsonl\") as test_file:\n",
    "    for line in test_file:\n",
    "        features = json.loads(line)\n",
    "        instruction = features[\"instruction\"]\n",
    "        response = features[\"response\"]\n",
    "        test_data_instruction.append(instruction)\n",
    "        test_data_response.append(response)\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "gemma_lm.summary()\n",
    "\n",
    "print(\"Before fine-tuning:\\n\\n\")\n",
    "\n",
    "# 示例\n",
    "with open(\"/kaggle/input/data-of-wyq1234/generate_text.jsonl\", \"r\") as generate_file:\n",
    "    for line in generate_file:\n",
    "        line = line.strip()  # 去掉首尾空白符\n",
    "        if not line:  # 跳过空行\n",
    "            continue\n",
    "        try:\n",
    "            features = json.loads(line)\n",
    "            instruction = features[\"instruction\"]\n",
    "            response = features[\"response\"]\n",
    "            prompt = template.format(\n",
    "                instruction=instruction,\n",
    "                response=\"\",\n",
    "            )\n",
    "            generate_data = gemma_lm.generate(prompt, max_length=512)\n",
    "            print('reference answer:')\n",
    "            print(response)\n",
    "            print('generate data:')  # 打印第一个response后的内容，strip去掉前后空格\n",
    "            print(generate_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"跳过格式错误的行: {line} 错误: {e}\")\n",
    "\n",
    "# 加载模型预测，得出初始模型在测试集上的rouge分数\n",
    "model_response = []\n",
    "for data in test_data_instruction:\n",
    "    prompt = template.format(\n",
    "        instruction=data,\n",
    "        response=\"\",\n",
    "    )\n",
    "    generate_data = gemma_lm.generate(prompt, max_length=512)\n",
    "    match = re.search(r\"回答:\\s*(.*?)(?=\\n问题:|$)\", generate_data, re.DOTALL)\n",
    "    s = str(match.group(1).strip()) if match else str(generate_data)\n",
    "    model_response.append(s)\n",
    "\n",
    "rouge_scores = evaluate_with_rouge(test_data_response, model_response)\n",
    "print(\"Rouge-1: %0.4f\" % rouge_scores[0])\n",
    "print(\"Rouge-L: %0.4f\" % rouge_scores[1])\n",
    "\n",
    "# 微调，启用Lora\n",
    "gemma_lm.backbone.enable_lora(rank=4)\n",
    "gemma_lm.summary()\n",
    "\n",
    "# 设置超参数\n",
    "gemma_lm.preprocessor.sequence_length = 256\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "# 微调\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "gemma_lm.fit(train_data, epochs=1, batch_size=1)  # batch_size太大GPU内存会不够\n",
    "gemma_lm.save('finetuned_model.keras')\n",
    "shutil.move('finetuned_model.keras', '/kaggle/working/finetuned_model.keras')\n",
    "gemma_lm.backbone.save_lora_weights(\"model.lora.h5\")\n",
    "shutil.move('model.lora.h5', '/kaggle/working/model.lora.h5')\n",
    "print(\"Lora weights saved.\")\n",
    "\n",
    "print(\"After fine-tuning:\\n\")\n",
    "\n",
    "# 示例对比\n",
    "with open(\"/kaggle/input/data-of-wyq1234/generate_text.jsonl\", \"r\") as generate_file:\n",
    "    for line in generate_file:\n",
    "        line = line.strip()  # 去掉首尾空白符\n",
    "        if not line:  # 跳过空行\n",
    "            continue\n",
    "        try:\n",
    "            features = json.loads(line)\n",
    "            instruction = features[\"instruction\"]\n",
    "            response = features[\"response\"]\n",
    "            prompt = template.format(\n",
    "                instruction=instruction,\n",
    "                response=\"\",\n",
    "            )\n",
    "            generate_data = gemma_lm.generate(prompt, max_length=512)\n",
    "            print('reference answer:')\n",
    "            print(response)\n",
    "            print('generate data:')  # 打印第一个response后的内容，strip去掉前后空格\n",
    "            print(generate_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"跳过格式错误的行: {line} 错误: {e}\")\n",
    "\n",
    "# 微调后模型的输出和测试集的参考输出对比后的分数\n",
    "\n",
    "# 加载模型预测，得出微调后模型在测试集上的rouge分数\n",
    "model_response_finetune = []\n",
    "for data in test_data_instruction:\n",
    "    prompt = template.format(\n",
    "        instruction=data,\n",
    "        response=\"\",\n",
    "    )\n",
    "    generate_data = gemma_lm.generate(prompt, max_length=512)\n",
    "    match = re.search(r\"回答:\\s*(.*?)(?=\\n问题:|$)\", generate_data, re.DOTALL)\n",
    "    s = str(match.group(1).strip()) if match else str(generate_data)\n",
    "    model_response_finetune.append(s)\n",
    "    # model_response_finetune.append(generate_data)\n",
    "\n",
    "# 计算ROUGE分数\n",
    "rouge_scores_finetune = evaluate_with_rouge(test_data_response, model_response_finetune)\n",
    "\n",
    "# 打印微调后ROUGE评分\n",
    "print(\"After fine-tuning:\")\n",
    "print(\"Rouge-1: %.4f\" % rouge_scores_finetune[0])\n",
    "print(\"Rouge-L: %.4f\" % rouge_scores_finetune[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f90203",
   "metadata": {
    "papermill": {
     "duration": 0.101502,
     "end_time": "2024-12-25T12:57:02.217035",
     "exception": false,
     "start_time": "2024-12-25T12:57:02.115533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code shows how to load saved lora parameters to use the fine-tuned model for inference:\n",
    "\n",
    "下述代码展示了如何加载保存的lora参数来使用微调后的模型进行推理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19007a95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-25T12:57:02.424279Z",
     "iopub.status.busy": "2024-12-25T12:57:02.423497Z",
     "iopub.status.idle": "2024-12-25T12:57:02.428015Z",
     "shell.execute_reply": "2024-12-25T12:57:02.427309Z"
    },
    "papermill": {
     "duration": 0.110055,
     "end_time": "2024-12-25T12:57:02.429607",
     "exception": false,
     "start_time": "2024-12-25T12:57:02.319552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import keras_nlp\n",
    "# import keras\n",
    "\n",
    "# # 加载基础模型\n",
    "# gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "\n",
    "# # 启用 Lora 参数支持\n",
    "# gemma_lm.backbone.enable_lora(rank=4)\n",
    "\n",
    "# # 加载微调后的 Lora 权重\n",
    "# lora_weights_path = \"/kaggle/working/model.lora.h5\"\n",
    "# gemma_lm.backbone.load_lora_weights(lora_weights_path)\n",
    "\n",
    "# # 确保加载的权重正确\n",
    "# gemma_lm.summary()\n",
    "\n",
    "# # 使用加载的模型进行推断\n",
    "# template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "# prompt = template.format(\n",
    "#     instruction=\"介绍一些中国的唐诗？\",\n",
    "#     response=\"\",\n",
    "# )\n",
    "# generate_data = gemma_lm.generate(prompt, max_length=256)\n",
    "# match = re.search(r\"Response:\\s*(.*?)(?=(\\nInstruction:|$))\", generate_data, re.DOTALL)\n",
    "# print(match.group(1).strip() if match else str(generate_data))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6372001,
     "sourceId": 10295321,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 3533,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1386.170854,
   "end_time": "2024-12-25T12:57:05.565719",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-25T12:33:59.394865",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
