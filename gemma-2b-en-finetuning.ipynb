{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dda95e8",
   "metadata": {
    "papermill": {
     "duration": 0.003065,
     "end_time": "2024-12-26T06:40:04.818078",
     "exception": false,
     "start_time": "2024-12-26T06:40:04.815013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Fintuning gemma_2b_en for simplified Chinese**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dde824",
   "metadata": {
    "papermill": {
     "duration": 0.002268,
     "end_time": "2024-12-26T06:40:04.823079",
     "exception": false,
     "start_time": "2024-12-26T06:40:04.820811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import neccessary package\n",
    "\n",
    "导入需要的库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57b7970",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-26T06:40:04.828996Z",
     "iopub.status.busy": "2024-12-26T06:40:04.828730Z",
     "iopub.status.idle": "2024-12-26T06:43:31.760318Z",
     "shell.execute_reply": "2024-12-26T06:43:31.759381Z"
    },
    "papermill": {
     "duration": 206.936976,
     "end_time": "2024-12-26T06:43:31.762455",
     "exception": false,
     "start_time": "2024-12-26T06:40:04.825479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c7b05ae9.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/758dc0ed.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/eab6ca9b.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/6d94291a.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/3864cda3.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/47534735.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/88ec62ec.json\" was modified by another program\r\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/eb045dd1.json\" was modified by another program\r\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\r\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\r\n",
      "nodefaults/linux-64 (check zst) ━━━━╸━━━━━━━━━━━━━━━╸━━━━   0.0 B Checking  0.0s\r\n",
      "nodefaults/noarch (check zst)   ━━━━━━━━━━━╸━━━━━━━━━━━━━   0.0 B Checking  0.0s\r\n",
      "rapidsai/noarch (check zst)     ━━━━━━━━━╸━━━━━━━━━━━━━━━   0.0 B Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\r\n",
      "nodefaults/linux-64 (check zst) ━━━━━╸━━━━━━━━━━━━━━━╸━━━   0.0 B Checking  0.1s\r\n",
      "nodefaults/noarch (check zst)   ━━━━━━━━━━━━╸━━━━━━━━━━━━   0.0 B Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\r\n",
      "nodefaults/linux-64 (check zst) ━━━━━━━╸━━━━━━━━━━━━━━━╸━   0.0 B Checking  0.2s\r\n",
      "nodefaults/noarch (check zst)   ━━━━━━━━━━━━━╸━━━━━━━━━━━   0.0 B Checking  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\r\n",
      "nodefaults/linux-64 (check zst) ━━━━━━━━╸━━━━━━━━━━━━━━━━   0.0 B Checking  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\r\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/linux-64                                   ??.?MB @  ??.?MB/s  0.0s\r\n",
      "nvidia/linux-64                                     ??.?MB @  ??.?MB/s  0.0s\r\n",
      "[+] 0.1s\r\n",
      "nodefaults/linux-64  \u001b[20m--\u001b[0m\u001b[1m\u001b[3m\u001b[5m\u001b[8m\u001b[38;2;000;000;000m\u001b[48;2;000;000;000m----------------\u001b[0m\u001b[20m-----\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "nodefaults/noarch    ---\u001b[38;2;000;092;044m----------------\u001b[0m----   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "nvidia/noarch        \u001b[1m\u001b[2m\u001b[7m\u001b[8m\u001b[9m\u001b[38;2;024;124;086m\u001b[48;2;162;193;044m----\u001b[0m\u001b[1m\u001b[5m\u001b[7m\u001b[8m\u001b[9m\u001b[38;2;015;050;046m\u001b[48;2;059;242;141m----------------\u001b[0m\u001b[1m\u001b[2m\u001b[7m\u001b[8m\u001b[9m\u001b[38;2;024;124;086m\u001b[48;2;162;193;044m---\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "rapidsai/noarch      \u001b[16m\u001b[48;2;138;188;224m--------------\u001b[0m\u001b[5m\u001b[9m\u001b[38;2;000;092;044m\u001b[48;2;000;000;000m---------\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\r\n",
      "conda-forge/linux-64 \u001b[38;2;123;202;064m\u001b[48;2;123;193;064m---------\u001b[0m\u001b[2m\u001b[4m\u001b[5m\u001b[7m\u001b[8m\u001b[00m\u001b[10m--------------\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch                                       ??.?MB @  ??.?MB/s  0.1s\r\n",
      "rapidsai/noarch                                     ??.?MB @  ??.?MB/s  0.0s\r\n",
      "[+] 0.2s\r\n",
      "nodefaults/linux-64  \u001b[20m----\u001b[0m\u001b[1m\u001b[3m\u001b[5m\u001b[8m\u001b[38;2;000;000;000m\u001b[48;2;000;000;000m----------------\u001b[0m\u001b[20m---\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\r\n",
      "nodefaults/noarch    -----\u001b[38;2;000;092;044m----------------\u001b[0m--   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m-\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m----------------------\u001b[0m   3.4MB /  40.9MB @  32.4MB/s  0.1s\r\n",
      "conda-forge/noarch   ━━━━━━━━━━━━━━━━━━━━━━━ 138.5kB /  18.0MB @   2.6MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnodefaults/noarch                                   ??.?MB @  ??.?MB/s  0.2s\r\n",
      "[+] 0.3s\r\n",
      "nodefaults/linux-64  \u001b[20m------\u001b[0m\u001b[1m\u001b[3m\u001b[5m\u001b[8m\u001b[38;2;000;000;000m\u001b[48;2;000;000;000m----------------\u001b[0m\u001b[20m-\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m----\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m-------------------\u001b[0m   8.2MB /  40.9MB @  40.0MB/s  0.2s\r\n",
      "conda-forge/noarch   ━━━━╸━━━━━━━━━━━━━━━━━━   4.3MB /  18.0MB @  27.9MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnodefaults/linux-64                                 ??.?MB @  ??.?MB/s  0.4s\r\n",
      "[+] 0.4s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m-----\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m------------------\u001b[0m  10.7MB /  40.9MB @  41.8MB/s  0.3s\r\n",
      "conda-forge/noarch   ━━━━━━━━━━╸━━━━━━━━━━━━   9.3MB /  18.0MB @  36.2MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m--------\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m---------------\u001b[0m  15.7MB /  40.9MB @  43.5MB/s  0.4s\r\n",
      "conda-forge/noarch   ━━━━━━━━━━━━━━━━━╸━━━━━  14.3MB /  18.0MB @  39.6MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m----------\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m-------------\u001b[0m  18.4MB /  40.9MB @  44.3MB/s  0.5s\r\n",
      "conda-forge/noarch   ━━━━━━━━━━━━━━━━━━━━╸━━  17.0MB /  18.0MB @  40.9MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  18.0MB @  40.9MB/s  0.5s\r\n",
      "[+] 0.7s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m-----------\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m------------\u001b[0m  20.2MB /  40.9MB @  36.3MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m----------------\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m-------\u001b[0m  29.9MB /  40.9MB @  45.3MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m----------------------\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m-\u001b[0m  39.8MB /  40.9MB @  52.3MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m----------------------\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m-\u001b[0m  39.8MB /  40.9MB @  52.3MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\r\n",
      "conda-forge/linux-64 \u001b[38;2;122;216;144m\u001b[48;2;122;236;064m----------------------\u001b[0m\u001b[38;2;123;202;064m\u001b[48;2;123;193;064m-\u001b[0m  39.8MB /  40.9MB @  52.3MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                40.9MB @  52.3MB/s  1.1s\r\n",
      "\u001b[?25h\r\n",
      "\r\n",
      "Transaction\r\n",
      "\r\n",
      "  Prefix: /opt/conda/envs/myenv\r\n",
      "\r\n",
      "  Updating specs:\r\n",
      "\r\n",
      "   - python=3.9\r\n",
      "\r\n",
      "\r\n",
      "  Package                Version  Build               Channel           Size\r\n",
      "──────────────────────────────────────────────────────────────────────────────\r\n",
      "  Install:\r\n",
      "──────────────────────────────────────────────────────────────────────────────\r\n",
      "\r\n",
      "  \u001b[32m+ _libgcc_mutex   \u001b[0m         0.1  conda_forge         conda-forge        3kB\r\n",
      "  \u001b[32m+ _openmp_mutex   \u001b[0m         4.5  2_gnu               conda-forge       24kB\r\n",
      "  \u001b[32m+ bzip2           \u001b[0m       1.0.8  h4bc722e_7          conda-forge      253kB\r\n",
      "  \u001b[32m+ ca-certificates \u001b[0m  2024.12.14  hbcca054_0          conda-forge      157kB\r\n",
      "  \u001b[32m+ ld_impl_linux-64\u001b[0m        2.43  h712a8e2_2          conda-forge      669kB\r\n",
      "  \u001b[32m+ libffi          \u001b[0m       3.4.2  h7f98852_5          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libgcc          \u001b[0m      14.2.0  h77fa898_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libgcc-ng       \u001b[0m      14.2.0  h69a702a_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libgomp         \u001b[0m      14.2.0  h77fa898_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ liblzma         \u001b[0m       5.6.3  hb9d3cd8_1          conda-forge      111kB\r\n",
      "  \u001b[32m+ libnsl          \u001b[0m       2.0.1  hd590300_0          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libsqlite       \u001b[0m      3.47.2  hee588c1_0          conda-forge      874kB\r\n",
      "  \u001b[32m+ libuuid         \u001b[0m      2.38.1  h0b41bf4_0          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libxcrypt       \u001b[0m      4.4.36  hd590300_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ libzlib         \u001b[0m       1.3.1  hb9d3cd8_2          conda-forge       61kB\r\n",
      "  \u001b[32m+ ncurses         \u001b[0m         6.5  he02047a_1          conda-forge      889kB\r\n",
      "  \u001b[32m+ openssl         \u001b[0m       3.4.0  hb9d3cd8_0          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ pip             \u001b[0m      24.3.1  pyh8b19718_2        conda-forge        1MB\r\n",
      "  \u001b[32m+ python          \u001b[0m      3.9.21  h9c0c6dc_1_cpython  conda-forge       24MB\r\n",
      "  \u001b[32m+ readline        \u001b[0m         8.2  h8228510_1          conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ setuptools      \u001b[0m      75.6.0  pyhff2d567_1        conda-forge      774kB\r\n",
      "  \u001b[32m+ tk              \u001b[0m      8.6.13  noxft_h4845f30_101  conda-forge\u001b[32m     Cached\u001b[0m\r\n",
      "  \u001b[32m+ tzdata          \u001b[0m       2024b  hc8b5060_0          conda-forge      122kB\r\n",
      "  \u001b[32m+ wheel           \u001b[0m      0.45.1  pyhd8ed1ab_1        conda-forge       63kB\r\n",
      "\r\n",
      "  Summary:\r\n",
      "\r\n",
      "  Install: 24 packages\r\n",
      "\r\n",
      "  Total download: 29MB\r\n",
      "\r\n",
      "──────────────────────────────────────────────────────────────────────────────\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Transaction starting\r\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\r\n",
      "Downloading      \u001b[96m\u001b[125m-\u001b[0m\u001b[10m----------------------\u001b[0m   0.0 B                            0.0s\r\n",
      "Extracting       \u001b[3m\u001b[4m\u001b[7m\u001b[112m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibsqlite                                          873.6kB @  ??.?MB/s  0.1s\r\n",
      "[+] 0.1s\r\n",
      "Downloading  (4) \u001b[96m\u001b[125m-\u001b[0m\u001b[10m----------------------\u001b[0m   1.9MB ncurses                    0.0s\r\n",
      "Extracting       \u001b[3m\u001b[4m\u001b[7m\u001b[112m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpip                                                  1.2MB @   5.6MB/s  0.1s\r\n",
      "ncurses                                            889.1kB @   1.4MB/s  0.1s\r\n",
      "setuptools                                         774.3kB @ 647.2kB/s  0.1s\r\n",
      "ca-certificates                                    157.1kB @  ??.?MB/s  0.0s\r\n",
      "ld_impl_linux-64                                   669.2kB @   6.9MB/s  0.1s\r\n",
      "bzip2                                              252.8kB @  ??.?MB/s  0.1s\r\n",
      "tzdata                                             122.4kB @  ??.?MB/s  0.0s\r\n",
      "liblzma                                            111.1kB @  ??.?MB/s  0.0s\r\n",
      "_openmp_mutex                                       23.6kB @  ??.?MB/s  0.0s\r\n",
      "[+] 0.2s\r\n",
      "Downloading  (4) \u001b[96m\u001b[125m-------------\u001b[0m\u001b[10m----------\u001b[0m  17.1MB _libgcc_mutex              0.1s\r\n",
      "Extracting   (8) ━━╸━━━━━━━━━━━━━╸\u001b[3m\u001b[4m\u001b[7m\u001b[112m━━━━━━\u001b[0m       2 _openmp_mutex              0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gwheel                                               62.9kB @  ??.?MB/s  0.0s\r\n",
      "libzlib                                             61.0kB @  ??.?MB/s  0.0s\r\n",
      "python                                              23.6MB @  87.0MB/s  0.2s\r\n",
      "_libgcc_mutex                                        2.6kB @  ??.?MB/s  0.0s\r\n",
      "[+] 0.3s\r\n",
      "Downloading      \u001b[96m\u001b[125m-----------------------\u001b[0m  28.9MB                            0.2s\r\n",
      "Extracting   (8) ━━━━━━━╸━━━━━━━━━━━━━╸\u001b[3m\u001b[4m\u001b[7m\u001b[112m━\u001b[0m       5 _openmp_mutex              0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\r\n",
      "Downloading      \u001b[96m\u001b[125m-----------------------\u001b[0m  28.9MB                            0.2s\r\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━╸━━━━━      11 ncurses                    0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\r\n",
      "Downloading      \u001b[96m\u001b[125m-----------------------\u001b[0m  28.9MB                            0.2s\r\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━╸━━━━      12 ncurses                    0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\r\n",
      "Downloading      \u001b[96m\u001b[125m-----------------------\u001b[0m  28.9MB                            0.2s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸━━      13 python                     0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\r\n",
      "Downloading      \u001b[96m\u001b[125m-----------------------\u001b[0m  28.9MB                            0.2s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸━━      13 python                     0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\r\n",
      "Downloading      \u001b[96m\u001b[125m-----------------------\u001b[0m  28.9MB                            0.2s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸━━      13 python                     0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hLinking _libgcc_mutex-0.1-conda_forge\r\n",
      "Linking ld_impl_linux-64-2.43-h712a8e2_2\r\n",
      "Linking ca-certificates-2024.12.14-hbcca054_0\r\n",
      "Linking libgomp-14.2.0-h77fa898_1\r\n",
      "Linking _openmp_mutex-4.5-2_gnu\r\n",
      "Linking libgcc-14.2.0-h77fa898_1\r\n",
      "Linking libzlib-1.3.1-hb9d3cd8_2\r\n",
      "Linking liblzma-5.6.3-hb9d3cd8_1\r\n",
      "Linking libgcc-ng-14.2.0-h69a702a_1\r\n",
      "Linking openssl-3.4.0-hb9d3cd8_0\r\n",
      "Linking libsqlite-3.47.2-hee588c1_0\r\n",
      "Linking libffi-3.4.2-h7f98852_5\r\n",
      "Linking tk-8.6.13-noxft_h4845f30_101\r\n",
      "Linking libxcrypt-4.4.36-hd590300_1\r\n",
      "Linking bzip2-1.0.8-h4bc722e_7\r\n",
      "Linking ncurses-6.5-he02047a_1\r\n",
      "Linking libuuid-2.38.1-h0b41bf4_0\r\n",
      "Linking libnsl-2.0.1-hd590300_0\r\n",
      "Linking readline-8.2-h8228510_1\r\n",
      "Linking tzdata-2024b-hc8b5060_0\r\n",
      "Linking python-3.9.21-h9c0c6dc_1_cpython\r\n",
      "Linking wheel-0.45.1-pyhd8ed1ab_1\r\n",
      "Linking setuptools-75.6.0-pyhff2d567_1\r\n",
      "Linking pip-24.3.1-pyh8b19718_2\r\n",
      "\r\n",
      "Transaction finished\r\n",
      "\r\n",
      "To activate this environment, use:\r\n",
      "\r\n",
      "    conda activate myenv\r\n",
      "\r\n",
      "Or to execute a single command in this environment, use:\r\n",
      "\r\n",
      "    conda run -n myenv mycommand\r\n",
      "\r\n",
      "Your parent process name is Name:\tpython.\r\n",
      "If your shell is xonsh, please use \"-s xonsh\".\r\n",
      "\r\n",
      "'conda' is running as a subprocess and can't modify the parent shell.\r\n",
      "Thus you must initialize your shell before using activate and deactivate.\r\n",
      "\r\n",
      "To initialize the current  shell, run:\r\n",
      "    $ eval \"$(conda shell hook --shell )\"\r\n",
      "and then activate or deactivate with:\r\n",
      "    $ conda activate\r\n",
      "To automatically initialize all future () shells, run:\r\n",
      "    $ conda shell init --shell  --root-prefix=~/.local/share/mamba\r\n",
      "If your shell was already initialized, reinitialize your shell with:\r\n",
      "    $ conda shell reinit --shell \r\n",
      "Otherwise, this may be an issue. In the meantime you can run commands. See:\r\n",
      "    $ conda run --help\r\n",
      "\r\n",
      "Supported shells are {bash, zsh, csh, posix, xonsh, cmd.exe, powershell, fish, nu}.\r\n",
      "\u001b[1m\u001b[41mcritical libmamba\u001b[m Shell not initialized\r\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /opt/conda/lib/python3.10/site-packages (2.16.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.62.2)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.3.3)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.37.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.26.4)\r\n",
      "Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.3.101 (from tensorflow[and-cuda])\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.43.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (0.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2024.6.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (3.1.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow[and-cuda]) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (2.1.5)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow[and-cuda]) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow[and-cuda]) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow[and-cuda]) (0.1.2)\r\n",
      "Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (412.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.6/412.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (14.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (22.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (24.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (867 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl (98.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl (125.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl (197.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.5/197.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "Successfully installed nvidia-cublas-cu12-12.3.4.1 nvidia-cuda-cupti-cu12-12.3.101 nvidia-cuda-nvcc-cu12-12.3.107 nvidia-cuda-nvrtc-cu12-12.3.107 nvidia-cuda-runtime-cu12-12.3.101 nvidia-cudnn-cu12-8.9.7.29 nvidia-cufft-cu12-11.0.12.1 nvidia-curand-cu12-10.3.4.107 nvidia-cusolver-cu12-11.5.4.101 nvidia-cusparse-cu12-12.2.0.103 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\r\n",
      "Collecting keras\r\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.11.0)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.3.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.12.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras) (3.1.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n",
      "Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: keras\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "Successfully installed keras-3.7.0\r\n",
      "Requirement already satisfied: keras-nlp in /opt/conda/lib/python3.10/site-packages (0.17.0)\r\n",
      "Collecting keras-nlp\r\n",
      "  Downloading keras_nlp-0.18.1-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting keras-hub==0.18.1 (from keras-nlp)\r\n",
      "  Downloading keras_hub-0.18.1-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (21.3)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (2024.5.15)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (13.7.1)\r\n",
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (0.3.4)\r\n",
      "Requirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (2.16.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (4.66.4)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-hub==0.18.1->keras-nlp) (3.1.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.18.1->keras-nlp) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.18.1->keras-nlp) (2.18.0)\r\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.16.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.18.1->keras-nlp) (0.1.2)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.3.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.62.2)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.7.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.37.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (2024.6.2)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.43.0)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.11.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.1.5)\r\n",
      "Downloading keras_nlp-0.18.1-py3-none-any.whl (2.0 kB)\r\n",
      "Downloading keras_hub-0.18.1-py3-none-any.whl (691 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.2/691.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: keras-hub, keras-nlp\r\n",
      "  Attempting uninstall: keras-hub\r\n",
      "    Found existing installation: keras-hub 0.17.0\r\n",
      "    Uninstalling keras-hub-0.17.0:\r\n",
      "      Successfully uninstalled keras-hub-0.17.0\r\n",
      "  Attempting uninstall: keras-nlp\r\n",
      "    Found existing installation: keras-nlp 0.17.0\r\n",
      "    Uninstalling keras-nlp-0.17.0:\r\n",
      "      Successfully uninstalled keras-nlp-0.17.0\r\n",
      "Successfully installed keras-hub-0.18.1 keras-nlp-0.18.1\r\n",
      "Collecting tensorrt\r\n",
      "  Downloading tensorrt-10.7.0.tar.gz (16 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting tensorrt_cu12==10.7.0 (from tensorrt)\r\n",
      "  Downloading tensorrt_cu12-10.7.0.tar.gz (18 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu12\r\n",
      "  Building wheel for tensorrt (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for tensorrt: filename=tensorrt-10.7.0-py2.py3-none-any.whl size=16337 sha256=ff502e913764f89d3796cff82d8b9e74fdb66277850d5de0303f5c1cd436c1e7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/da/cb/16/d5add64df498ec418cc9eb2885dc828a67a002afc30873d932\r\n",
      "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.7.0-py2.py3-none-any.whl size=17550 sha256=4ecc0a43bae87fca2540ac7a303fc8139f042402a0deb60bbeec357103984f2c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/dd/9d/413a390ab4b9ebf16701f91cecf9d94a2d481ea2949bcd72e9\r\n",
      "Successfully built tensorrt tensorrt_cu12\r\n",
      "Installing collected packages: tensorrt_cu12, tensorrt\r\n",
      "Successfully installed tensorrt-10.7.0 tensorrt_cu12-10.7.0\r\n"
     ]
    }
   ],
   "source": [
    "!conda create -n myenv python=3.9 -y\n",
    "!conda activate myenv\n",
    "!pip install \"tensorflow[and-cuda]\"\n",
    "!pip install -U keras\n",
    "!pip install -U keras-nlp\n",
    "!pip install tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c868e",
   "metadata": {
    "papermill": {
     "duration": 0.036341,
     "end_time": "2024-12-26T06:43:31.836587",
     "exception": false,
     "start_time": "2024-12-26T06:43:31.800246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import metric using rouge \n",
    "\n",
    "导入评估所需库使用rouge指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8f1cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T06:43:31.910880Z",
     "iopub.status.busy": "2024-12-26T06:43:31.910557Z",
     "iopub.status.idle": "2024-12-26T06:43:50.109167Z",
     "shell.execute_reply": "2024-12-26T06:43:50.108300Z"
    },
    "papermill": {
     "duration": 18.238094,
     "end_time": "2024-12-26T06:43:50.111202",
     "exception": false,
     "start_time": "2024-12-26T06:43:31.873108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\r\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\r\n",
      "Building wheels for collected packages: rouge-score\r\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=54781c8c8b13eaf177be2aedc65128e9b4c2e7b5019f0b832d5c0b21e5d2e0e0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\r\n",
      "Successfully built rouge-score\r\n",
      "Installing collected packages: rouge-score\r\n",
      "Successfully installed rouge-score-0.1.2\r\n",
      "Collecting rouge-chinese\r\n",
      "  Downloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge-chinese) (1.16.0)\r\n",
      "Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\r\n",
      "Installing collected packages: rouge-chinese\r\n",
      "Successfully installed rouge-chinese-1.0.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score\n",
    "!pip install rouge-chinese"
   ]
  },
  {
   "attachments": {
    "bdd47968-dc56-45cb-acd1-dc2653617bc8.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "eea38f8c",
   "metadata": {
    "papermill": {
     "duration": 0.037336,
     "end_time": "2024-12-26T06:43:50.186093",
     "exception": false,
     "start_time": "2024-12-26T06:43:50.148757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code is evaluated using rouge metrics, including rouge1 and rougeL metrics.\n",
    "\n",
    "**ROUGE-1 (Rouge-1)**\n",
    "\n",
    "ROUGE-1 is a special case of ROUGE-N, focusing on the recall rate of 1-gram (single word). It calculates the ratio of the number of 1-grams shared between the automatically generated abstracts (candidate abstracts) and the reference abstracts to the total number of 1-grams in the reference abstracts. To be specific:\n",
    "\n",
    "* Molecule: The number of 1-grams that appear in both candidate abstracts and reference abstracts.\n",
    "* Denominator: The number of 1-grams of the reference summary. The formula for calculating ROUGE-1 can be expressed as: ROUGE-1 = Count Match/Reference Count\n",
    "\n",
    "Where, Count Match is the maximum number of 1-grams shared by the candidate digest and the Reference digest, and Reference Count is the total number of 1-grams in the reference digest. ROUGE-1 intuitively and concisely reflects word order, and is suitable for short summary evaluation and multi-document summary (without stopping word conditions).\n",
    "\n",
    "**ROUGE-L (Rouge-L)**\n",
    "\n",
    "ROUGE-L is an evaluation metric based on the Longest Common Subsequence (LCS). It calculates the length of the longest common subsequence between the automatically generated summary and the reference summary and measures the similarity between the two. To be specific:\n",
    "\n",
    "* LCS(X, Y) : The length of the longest common subsequence of X and Y.\n",
    "* m, n: indicates the length of the reference summary and the automatic summary, respectively (generally the number of words included).\n",
    "* Rlcs, Plcs: Recall rate and accuracy, respectively.\n",
    "* Flcs: ROUGE-L is an F-measure of recall rate and accuracy.\n",
    "\n",
    "* The calculation formula of ROUGE-L can be expressed as:![微信截图_20241224120237.png](attachment:bdd47968-dc56-45cb-acd1-dc2653617bc8.png)\n",
    "\n",
    "Among them, beta is a parameter used to balance recall rates and accuracy, usually set to a larger number, so that ROUGE-L considers almost only recall rates. This is in contrast to the general evaluation method that only considers the recall rate.\n",
    "\n",
    "评估代码，使用的是rouge指标，包括rouge1和rougeL指标。\n",
    "\n",
    "**ROUGE-1 (Rouge-1)**\n",
    "\n",
    "ROUGE-1是ROUGE-N的一个特例，专注于1-gram（单个词）的召回率。它计算的是自动生成的摘要（候选摘要）与参考摘要之间共有的1-gram的数量与参考摘要中1-gram总数的比例。具体来说：\n",
    "\n",
    "* 分子：候选摘要和参考摘要都出现的1-gram的个数。\n",
    "* 分母：参考摘要的1-gram个数。ROUGE-1的计算公式可以表示为：ROUGE-1 = Count Match / Reference Count\n",
    "\n",
    "其中，Count Match是候选摘要和参考摘要共有的1-gram的最大数量，Reference Count是参考摘要中1-gram的总数量。ROUGE-1能够直观、简洁地反映词序，适用于短摘要评估和多文档摘要（去停用词条件）。\n",
    "\n",
    "**ROUGE-L (Rouge-L)**\n",
    "\n",
    "ROUGE-L是基于最长公共子序列（Longest Common Subsequence, LCS）的评估指标。它计算自动生成的摘要与参考摘要之间的最长公共子序列的长度，并以此来衡量两者的相似度。具体来说：\n",
    "\n",
    "* LCS(X, Y)：X和Y的最长公共子序列的长度。\n",
    "* m, n：分别表示参考摘要和自动摘要的长度（一般就是所含词的个数）。\n",
    "* Rlcs, Plcs：分别表示召回率和准确率。\n",
    "* Flcs：即ROUGE-L，是召回率和准确率的F-measure。\n",
    "  \n",
    "* ROUGE-L的计算公式可以表示为：![微信截图_20241224120237.png](attachment:bdd47968-dc56-45cb-acd1-dc2653617bc8.png)\n",
    "\n",
    "其中，β是一个用于平衡召回率和准确率的参数，通常设置为一个较大的数，使得ROUGE-L几乎只考虑召回率。这与一般只考虑召回率的评估方法相对应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f707db00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T06:43:50.261380Z",
     "iopub.status.busy": "2024-12-26T06:43:50.261029Z",
     "iopub.status.idle": "2024-12-26T06:43:50.513283Z",
     "shell.execute_reply": "2024-12-26T06:43:50.512615Z"
    },
    "papermill": {
     "duration": 0.292241,
     "end_time": "2024-12-26T06:43:50.515207",
     "exception": false,
     "start_time": "2024-12-26T06:43:50.222966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rouge_chinese import Rouge\n",
    "import jieba\n",
    "\n",
    "def evaluate_with_rouge(reference_list, generated_list):\n",
    "    # 创建ROUGE对象\n",
    "    rouge = Rouge()\n",
    "\n",
    "    # 存储ROUGE评分的列表\n",
    "    rouge1_scores = []\n",
    "    rougeL_scores = []\n",
    "\n",
    "    # 遍历每一对字符串，计算ROUGE评分\n",
    "    for reference, generated in zip(reference_list, generated_list):\n",
    "        reference = ' '.join(jieba.cut(reference))\n",
    "        generated = ' '.join(jieba.cut(generated))\n",
    "        scores = rouge.get_scores(reference, generated)\n",
    "        # 将每个ROUGE评分的F1值添加到列表中\n",
    "        rouge1_scores.append(scores[0]['rouge-1'][\"f\"])\n",
    "        rougeL_scores.append(scores[0]['rouge-l'][\"f\"])\n",
    "\n",
    "    # 计算ROUGE-1和ROUGE-L的平均F1值\n",
    "    avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores) if rouge1_scores else 0\n",
    "    avg_rougeL = sum(rougeL_scores) / len(rougeL_scores) if rougeL_scores else 0\n",
    "\n",
    "    # 返回平均分数\n",
    "    return avg_rouge1, avg_rougeL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b28c1",
   "metadata": {
    "papermill": {
     "duration": 0.0362,
     "end_time": "2024-12-26T06:43:50.588981",
     "exception": false,
     "start_time": "2024-12-26T06:43:50.552781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The fine-tuned data includes data related to Chinese history, geography, and literature, with particular attention to the reading comprehension of literature, the understanding of Chinese culture, and the generated content of Chinese literature, which is derived from the generated data of existing high-quality large models. The data includes historical knowledge and literary knowledge, and focuses on literary reading comprehension and literary text generation data (including the understanding and creation of ancient poetry, the understanding and creation of ancient texts and the understanding and creation of modern poetry and articles).\n",
    "\n",
    "In the input dataset file, the generate_text.jsonl file is used for example comparison of the output before and after model fine-tuning, and the test.jsonl file is used for evaluation of the model output using rouge metrics. The file zh_seed_tasts.jsonl contains more than 1000 training data for fine-tuning the model.\n",
    "\n",
    "微调的数据中包含中国的历史、地理、文学相关的数据，尤其关注了文学的阅读理解、中国文化理解以及中国文学生成内容，来源于与现有高质量大模型的生成数据。数据包括历史知识、文学知识，同时着重关注了文学阅读理解以及文学文本生成数据（包含古代诗歌的理解和创作、古文的理解和创作以及现代诗歌和文章的理解和创作）。\n",
    "\n",
    "在输入的数据集文件中，generate_text.jsonl文件用于模型微调前后的输出做示例来对比，test.jsonl文件则用于对模型输出使用rouge指标来评估，zh_seed_tasts.jsonl文件则包含1000多条训练数据用于对模型微调的训练。\n",
    "\n",
    "Our fine tuning technology uses lora low rank adaptation to make fine tuning faster.\n",
    "lora steps:\n",
    "* Freeze the weight of the pre-trained model, leaving it unchanged.\n",
    "* Based on the pre-trained model, add two low-rank matrices A and B, and the product of these two matrices will be used to simulate the effect of full-parameter fine-tuning.\n",
    "* During training, only matrices A and B are updated, while the parameters of the pre-trained model remain unchanged.\n",
    "* After the training is complete, multiply the B matrix with the A matrix and merge the results into the parameters of the pre-trained model to get the fine-tuned model.\n",
    "\n",
    "The fine-tuned code is as follows:\n",
    "\n",
    "我们的微调技术使用的是lora低秩适应，使得微调速度加快。\n",
    "lora的步骤：\n",
    "* 冻结预训练模型的权重，保持不变。\n",
    "* 在预训练模型的基础上，增加两个低秩矩阵A和B，这两个矩阵的乘积将用于模拟全参数微调的效果。\n",
    "* 在训练过程中，仅对矩阵A和B进行更新，而预训练模型的参数保持不变。\n",
    "* 训练完成后，将B矩阵与A矩阵相乘，并将结果合并到预训练模型的参数中，得到微调后的模型。\n",
    "\n",
    "微调的代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97844e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T06:43:50.663957Z",
     "iopub.status.busy": "2024-12-26T06:43:50.663655Z",
     "iopub.status.idle": "2024-12-26T07:42:22.056676Z",
     "shell.execute_reply": "2024-12-26T07:42:22.055740Z"
    },
    "papermill": {
     "duration": 3511.84311,
     "end_time": "2024-12-26T07:42:22.468509",
     "exception": false,
     "start_time": "2024-12-26T06:43:50.625399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fine-tuning:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735195512.936716      23 service.cc:145] XLA service 0x5bf0aa224e80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735195512.936764      23 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1735195520.659546      23 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference answer:\n",
      "静夜思\n",
      "generate data:\n",
      "问题:\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "回答:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，疑是地上霜。’是《雪中悍刀行》第一首诗的内容。\n",
      "\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "答案:\n",
      "‘床前明月光，\n",
      "reference answer:\n",
      "文章主要描述了滁州西南的醉翁亭及其周围的自然风光，表达了作者与民同乐的情怀。\n",
      "generate data:\n",
      "问题:\n",
      "根据以下古文，概括其主要内容：文言文标题: 醉翁亭记 作者: 欧阳修 正文: 环滁皆山也。\n",
      "\n",
      "回答:\n",
      "1. 醉翁亭记是古文，是古诗。\n",
      "2. 醉翁亭记是古诗，是古文。\n",
      "3. 醉翁亭记是古文，是古诗。\n",
      "4. 醉翁亭记是古诗，是古文。\n",
      "5. 醉翁亭记是古诗，是古文。\n",
      "6. 醉翁亭记是古文，是古诗。\n",
      "7. 醉翁亭记是古诗，是古文。\n",
      "8. 醉翁亭记是古文，是古诗。\n",
      "9. 醉翁亭记是古诗，是古文。\n",
      "10. 醉翁亭记是古文，是古诗。\n",
      "11. 醉翁亭记是古诗，是古文。\n",
      "12. 醉翁亭记是古文，是古诗。\n",
      "13. 醉翁亭记是古诗，是古文。\n",
      "14. 醉翁亭记是古文，是古诗。\n",
      "15. 醉翁亭记是古诗，是古文。\n",
      "16. 醉翁亭记是古文，是古诗。\n",
      "17. 醉翁亭记是古诗，是古文。\n",
      "18. 醉翁亭记是古文，是古诗。\n",
      "19. 醉翁亭记是古诗，是古文。\n",
      "20. 醉翁亭记是古文，是古诗。\n",
      "21. 醉翁亭记是古诗，是古文。\n",
      "22. 醉翁亭记是古文，是古诗。\n",
      "23. 醉翁亭记是古诗，是古文。\n",
      "24. 醉翁亭记是古文，是古诗。\n",
      "25. 醉翁亭记是古诗，是古文。\n",
      "26. 醉翁亭记是古文，是古诗。\n",
      "27. 醉翁亭记是古诗，是古文。\n",
      "28. 醉翁亭记是古文，是古诗。\n",
      "29\n",
      "reference answer:\n",
      "这首词用词极为叠沓，强调了作者内心的孤独与悲痛，充分表现了情感的深沉与无助。\n",
      "generate data:\n",
      "问题:\n",
      "阅读以下宋词，并分析其用词特点：词牌名: 声声慢 作者: 李清照 正文: 寻寻觅觅，冷冷清清，凄凄惨惨戚戚。\n",
      "\n",
      "回答:\n",
      "1.词牌名: 声声慢\n",
      "2.词牌名: 觅觅\n",
      "3.词牌名: 戚戚\n",
      "4.词牌名: 惨惨\n",
      "5.词牌名: 凄凄\n",
      "6.词牌名: 觅觅\n",
      "7.词牌名: 戚戚\n",
      "8.词牌名: 惨惨\n",
      "9.词牌名: 凄凄\n",
      "10.词牌名: 觅觅\n",
      "11.词牌名: 戚戚\n",
      "12.词牌名: 惨惨\n",
      "13.词牌名: 凄凄\n",
      "14.词牌名: 觅觅\n",
      "15.词牌名: 戚戚\n",
      "16.词牌名: 惨惨\n",
      "17.词牌名: 凄凄\n",
      "18.词牌名: 觅觅\n",
      "19.词牌名: 戚戚\n",
      "20.词牌名: 惨惨\n",
      "21.词牌名: 凄凄\n",
      "22.词牌名: 觅觅\n",
      "23.词牌名: 戚戚\n",
      "24.词牌名: 惨惨\n",
      "25.词牌名: 凄凄\n",
      "26.词牌名: 觅觅\n",
      "27.词牌名: 戚戚\n",
      "28.词牌名: 惨惨\n",
      "29.词牌名: 凄凄\n",
      "30.词牌名: 觅觅\n",
      "31.词牌名: 戚戚\n",
      "32.词牌名: 惨惨\n",
      "33.词牌名: 凄凄\n",
      "34.词牌名: 觅觅\n",
      "35.词牌名: 戚戚\n",
      "36.词牌名: 惨惨\n",
      "37.词牌名: 凄凄\n",
      "38.词牌名: 觅觅\n",
      "39.词牌名: 戚戚\n",
      "40.词牌名: 惨惨\n",
      "41.词牌名: 凄凄\n",
      "42.词牌名: 觅觅\n",
      "43.词牌名:\n",
      "reference answer:\n",
      "山间溪流潺潺，桃花片片随风飘落，点缀在青翠的草地上。四周群山环绕，鸟鸣声声，宛若世外桃源。远处竹林深深，似有炊烟袅袅升起，一切宁静而美好。\n",
      "generate data:\n",
      "问题:\n",
      "根据题目‘桃花源记’，写一段描写桃花源景色的文字。\n",
      "\n",
      "回答:\n",
      "桃花源记是鲁迅的代表作之一，描写了鲁迅的童年，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年生活，描述了鲁迅的童年\n",
      "reference answer:\n",
      "渔舟摇夕影，歌起晚风轻。\n",
      "水色天光共，归途满笛声。\n",
      "generate data:\n",
      "问题:\n",
      "以‘渔舟唱晚’为主题，创作一首五言绝句。\n",
      "\n",
      "回答:\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔舟唱晚，\n",
      "渔\n",
      "reference answer:\n",
      "老街的记忆，是那些斑驳的墙面，是那些回响在小巷中的笑声，是那些岁月带不走的温暖。\n",
      "generate data:\n",
      "问题:\n",
      "以‘老街的记忆’为题，创作一段怀旧风格的散文。\n",
      "\n",
      "回答:\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老街的记忆\n",
      "老\n",
      "reference answer:\n",
      "丝绸之路是连接中西方的重要贸易通道，促进了文化交流与经济繁荣。\n",
      "generate data:\n",
      "问题:\n",
      "简述‘丝绸之路’在古代贸易中的作用。\n",
      "\n",
      "回答:\n",
      "丝绸之路是古代丝绸贸易的通道，是丝绸贸易的“丝路”。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟，是丝绸贸易的开端。丝绸之路的开辟\n",
      "reference answer:\n",
      "‘欲穷千里目，更上一层楼’寓意着只有登上更高的境界，才能看到更远的风景，象征着追求卓越和超越自我的精神。\n",
      "generate data:\n",
      "问题:\n",
      "解释以下古诗中‘欲穷千里目，更上一层楼’的寓意：古诗标题: 登鹳雀楼 作者: 王之涣 正文: 白日依山尽，黄河入海流。欲穷千里目，更上一层楼。\n",
      "\n",
      "回答:\n",
      "古诗标题: 登鹳雀楼\n",
      "作者: 王之涣\n",
      "原文: 白日依山尽，黄河入海流。欲穷千里目，更上一层楼。\n",
      "\n",
      "解题思路:\n",
      "1. 题目中‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘欲穷千里目’的寓意是‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.658 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1: 0.1946\n",
      "Rouge-L: 0.0280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1735195921.190635     207 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735195932.134887     207 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_9', 436 bytes spill stores, 508 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_6', 436 bytes spill stores, 508 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1559/1559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 371ms/step - loss: 0.5036 - sparse_categorical_accuracy: 0.4758\n",
      "Epoch 2/5\n",
      "\u001b[1m1559/1559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 371ms/step - loss: 0.4235 - sparse_categorical_accuracy: 0.5661\n",
      "Epoch 3/5\n",
      "\u001b[1m1559/1559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 370ms/step - loss: 0.4000 - sparse_categorical_accuracy: 0.5886\n",
      "Epoch 4/5\n",
      "\u001b[1m1559/1559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 370ms/step - loss: 0.3786 - sparse_categorical_accuracy: 0.6083\n",
      "Epoch 5/5\n",
      "\u001b[1m1559/1559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 370ms/step - loss: 0.3608 - sparse_categorical_accuracy: 0.6230\n",
      "Lora weights saved.\n",
      "After fine-tuning:\n",
      "\n",
      "reference answer:\n",
      "静夜思\n",
      "generate data:\n",
      "问题:\n",
      "‘床前明月光，疑是地上霜。’是哪首诗的内容？\n",
      "\n",
      "回答:\n",
      "‘床前明月光’为‘诗集’《古诗选》中的诗歌。\n",
      "reference answer:\n",
      "文章主要描述了滁州西南的醉翁亭及其周围的自然风光，表达了作者与民同乐的情怀。\n",
      "generate data:\n",
      "问题:\n",
      "根据以下古文，概括其主要内容：文言文标题: 醉翁亭记 作者: 欧阳修 正文: 环滁皆山也。\n",
      "\n",
      "回答:\n",
      "这篇文章描写了作者在醉翁亭的经历，描绘了亭中清幽的氛围，以及作者的内心深处的感受。\n",
      "reference answer:\n",
      "这首词用词极为叠沓，强调了作者内心的孤独与悲痛，充分表现了情感的深沉与无助。\n",
      "generate data:\n",
      "问题:\n",
      "阅读以下宋词，并分析其用词特点：词牌名: 声声慢 作者: 李清照 正文: 寻寻觅觅，冷冷清清，凄凄惨惨戚戚。\n",
      "\n",
      "回答:\n",
      "这首词用词简洁，表达了清照在孤寂中寻找爱人的悲切情感。\n",
      "reference answer:\n",
      "山间溪流潺潺，桃花片片随风飘落，点缀在青翠的草地上。四周群山环绕，鸟鸣声声，宛若世外桃源。远处竹林深深，似有炊烟袅袅升起，一切宁静而美好。\n",
      "generate data:\n",
      "问题:\n",
      "根据题目‘桃花源记’，写一段描写桃花源景色的文字。\n",
      "\n",
      "回答:\n",
      "桃花源是桃花源记的主题，是一个理想的乡间小世界。桃花源的景色既有清澈的河水，又有绿叶茂密的树林。在桃花源，人们的生活节奏是慢的，生活中的每一个细节都带有浓浓的乡土气息。\n",
      "reference answer:\n",
      "渔舟摇夕影，歌起晚风轻。\n",
      "水色天光共，归途满笛声。\n",
      "generate data:\n",
      "问题:\n",
      "以‘渔舟唱晚’为主题，创作一首五言绝句。\n",
      "\n",
      "回答:\n",
      "渔舟唱晚，渔翁闲鱼。\n",
      "渔火映水，渔翁闲鱼。\n",
      "渔舟唱晚，渔翁闲鱼。\n",
      "渔火映水，渔翁闲鱼。\n",
      "reference answer:\n",
      "老街的记忆，是那些斑驳的墙面，是那些回响在小巷中的笑声，是那些岁月带不走的温暖。\n",
      "generate data:\n",
      "问题:\n",
      "以‘老街的记忆’为题，创作一段怀旧风格的散文。\n",
      "\n",
      "回答:\n",
      "老街的记忆，是时光的流淌，是时光的留存。\n",
      "每当我走过，旧时光的记忆，如潮水般涌起，如潮水般流淌。\n",
      "每当我停下来，旧时光的记忆，如潮水般停滞，如潮水般留存。\n",
      "每当我 zatrzy，旧时光的记忆，如潮水般停滞，如潮水般留存。\n",
      "reference answer:\n",
      "丝绸之路是连接中西方的重要贸易通道，促进了文化交流与经济繁荣。\n",
      "generate data:\n",
      "问题:\n",
      "简述‘丝绸之路’在古代贸易中的作用。\n",
      "\n",
      "回答:\n",
      "丝绸之路是古代贸易的重要通道， connecting丝绸之路连接了东亚和西欧，促进了文化交流和经济合作。\n",
      "reference answer:\n",
      "‘欲穷千里目，更上一层楼’寓意着只有登上更高的境界，才能看到更远的风景，象征着追求卓越和超越自我的精神。\n",
      "generate data:\n",
      "问题:\n",
      "解释以下古诗中‘欲穷千里目，更上一层楼’的寓意：古诗标题: 登鹳雀楼 作者: 王之涣 正文: 白日依山尽，黄河入海流。欲穷千里目，更上一层楼。\n",
      "\n",
      "回答:\n",
      "‘欲穷千里目，更上一层楼’寓意了远方遥远的远景，以及对人生的追求与超越。\n",
      "After fine-tuning:\n",
      "Rouge-1: 0.2741\n",
      "Rouge-L: 0.2063\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import keras\n",
    "import keras_nlp\n",
    "import re\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"wyq1234597\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"b3439dbc7b41a30c50a40b6b44613c06\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n",
    "\n",
    "template = \"问题:\\n{instruction}\\n\\n回答:\\n{response}\"\n",
    "\n",
    "# 加载训练集(json)格式(问答)\n",
    "train_data = []\n",
    "with open(\"/kaggle/input/d/wyq1234597/data-of-wyq1234/zh_seed_tasks.jsonl\") as tarin_file:\n",
    "    for line in tarin_file:\n",
    "        line = line.strip()  # 去掉首尾空白符\n",
    "        if not line:  # 跳过空行\n",
    "            continue\n",
    "        try:\n",
    "            features = json.loads(line)\n",
    "            # template_qa = \"问题:\\n{instruction}\\n\\n回答:\\n{response}\"\n",
    "            instruction = features[\"instruction\"]\n",
    "            response = features[\"response\"]\n",
    "            train_data.append(template.format(instruction=instruction, response=response))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"跳过格式错误的行: {line} 错误: {e}\")\n",
    "\n",
    "# 加载测试集(json)，分别存为指令以及响应\n",
    "test_data_instruction = []\n",
    "test_data_response = []\n",
    "with open(\"/kaggle/input/d/wyq1234597/data-of-wyq1234/test.jsonl\") as test_file:\n",
    "    for line in test_file:\n",
    "        features = json.loads(line)\n",
    "        instruction = features[\"instruction\"]\n",
    "        response = features[\"response\"]\n",
    "        test_data_instruction.append(instruction)\n",
    "        test_data_response.append(response)\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "gemma_lm.summary()\n",
    "\n",
    "print(\"Before fine-tuning:\\n\\n\")\n",
    "\n",
    "# 示例\n",
    "with open(\"/kaggle/input/d/wyq1234597/data-of-wyq1234/generate_text.jsonl\", \"r\") as generate_file:\n",
    "    for line in generate_file:\n",
    "        line = line.strip()  # 去掉首尾空白符\n",
    "        if not line:  # 跳过空行\n",
    "            continue\n",
    "        try:\n",
    "            features = json.loads(line)\n",
    "            instruction = features[\"instruction\"]\n",
    "            response = features[\"response\"]\n",
    "            prompt = template.format(\n",
    "                instruction=instruction,\n",
    "                response=\"\",\n",
    "            )\n",
    "            generate_data = gemma_lm.generate(prompt, max_length=512)\n",
    "            match = re.search(r\"回答：\\s*(.*?)(?=\\n问题：|$)\", generate_data, re.DOTALL)\n",
    "            s = str(match.group(1).strip()) if match else str(generate_data)\n",
    "            print('reference answer:')\n",
    "            print(response)\n",
    "            print('generate data:')  # 打印第一个response后的内容，strip去掉前后空格\n",
    "            print(s if match else generate_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"跳过格式错误的行: {line} 错误: {e}\")\n",
    "\n",
    "# 加载模型预测，得出初始模型在测试集上的rouge分数\n",
    "model_response = []\n",
    "for data in test_data_instruction:\n",
    "    prompt = template.format(\n",
    "        instruction=data,\n",
    "        response=\"\",\n",
    "    )\n",
    "    generate_data = gemma_lm.generate(prompt, max_length=512)\n",
    "    match = re.search(r\"回答：\\s*(.*?)(?=\\n问题：|$)\", generate_data, re.DOTALL)\n",
    "    s = str(match.group(1).strip()) if match else str(generate_data)\n",
    "    model_response.append(s)\n",
    "\n",
    "rouge_scores = evaluate_with_rouge(test_data_response, model_response)\n",
    "print(\"Rouge-1: %0.4f\" % rouge_scores[0])\n",
    "print(\"Rouge-L: %0.4f\" % rouge_scores[1])\n",
    "\n",
    "# 微调，启用Lora\n",
    "gemma_lm.backbone.enable_lora(rank=4)\n",
    "gemma_lm.summary()\n",
    "\n",
    "# 设置超参数\n",
    "gemma_lm.preprocessor.sequence_length = 256\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "# 微调\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "gemma_lm.fit(train_data, epochs=5, batch_size=1)  # batch_size太大GPU内存会不够\n",
    "gemma_lm.save('finetuned_model.keras')\n",
    "shutil.move('finetuned_model.keras', '/kaggle/working/finetuned_model.keras')\n",
    "gemma_lm.backbone.save_lora_weights(\"model.lora.h5\")\n",
    "shutil.move('model.lora.h5', '/kaggle/working/model.lora.h5')\n",
    "print(\"Lora weights saved.\")\n",
    "\n",
    "print(\"After fine-tuning:\\n\")\n",
    "\n",
    "# 示例对比\n",
    "with open(\"/kaggle/input/d/wyq1234597/data-of-wyq1234/generate_text.jsonl\", \"r\") as generate_file:\n",
    "    for line in generate_file:\n",
    "        line = line.strip()  # 去掉首尾空白符\n",
    "        if not line:  # 跳过空行\n",
    "            continue\n",
    "        try:\n",
    "            features = json.loads(line)\n",
    "            instruction = features[\"instruction\"]\n",
    "            response = features[\"response\"]\n",
    "            prompt = template.format(\n",
    "                instruction=instruction,\n",
    "                response=\"\",\n",
    "            )\n",
    "            generate_data = gemma_lm.generate(prompt, max_length=512)\n",
    "            match = re.search(r\"回答：\\s*(.*?)(?=\\n问题：|$)\", generate_data, re.DOTALL)\n",
    "            s = str(match.group(1).strip()) if match else str(generate_data)\n",
    "            print('reference answer:')\n",
    "            print(response)\n",
    "            print('generate data:')  # 打印第一个response后的内容，strip去掉前后空格\n",
    "            print(s if match else generate_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"跳过格式错误的行: {line} 错误: {e}\")\n",
    "\n",
    "# 微调后模型的输出和测试集的参考输出对比后的分数\n",
    "\n",
    "# 加载模型预测，得出微调后模型在测试集上的rouge分数\n",
    "model_response_finetune = []\n",
    "for data in test_data_instruction:\n",
    "    prompt = template.format(\n",
    "        instruction=data,\n",
    "        response=\"\",\n",
    "    )\n",
    "    generate_data = gemma_lm.generate(prompt, max_length=512)\n",
    "    match = re.search(r\"回答：\\s*(.*?)(?=\\n问题：|$)\", generate_data, re.DOTALL)\n",
    "    s = str(match.group(1).strip()) if match else str(generate_data)\n",
    "    model_response_finetune.append(s)\n",
    "    # model_response_finetune.append(generate_data)\n",
    "\n",
    "# 计算ROUGE分数\n",
    "rouge_scores_finetune = evaluate_with_rouge(test_data_response, model_response_finetune)\n",
    "\n",
    "# 打印微调后ROUGE评分\n",
    "print(\"After fine-tuning:\")\n",
    "print(\"Rouge-1: %.4f\" % rouge_scores_finetune[0])\n",
    "print(\"Rouge-L: %.4f\" % rouge_scores_finetune[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a8b5f",
   "metadata": {
    "papermill": {
     "duration": 0.398194,
     "end_time": "2024-12-26T07:42:23.313404",
     "exception": false,
     "start_time": "2024-12-26T07:42:22.915210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code shows how to load saved lora parameters to use the fine-tuned model for inference:\n",
    "\n",
    "下述代码展示了如何加载保存的lora参数来使用微调后的模型进行推理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42c65c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T07:42:24.161002Z",
     "iopub.status.busy": "2024-12-26T07:42:24.160602Z",
     "iopub.status.idle": "2024-12-26T07:42:24.165457Z",
     "shell.execute_reply": "2024-12-26T07:42:24.164585Z"
    },
    "papermill": {
     "duration": 0.405515,
     "end_time": "2024-12-26T07:42:24.167154",
     "exception": false,
     "start_time": "2024-12-26T07:42:23.761639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import keras_nlp\n",
    "# import keras\n",
    "# import re\n",
    "# # 加载基础模型\n",
    "# gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "\n",
    "# # 启用 Lora 参数支持\n",
    "# gemma_lm.backbone.enable_lora(rank=4)\n",
    "\n",
    "# # 加载微调后的 Lora 权重\n",
    "# lora_weights_path = \"/kaggle/input/fintuned-lora/keras/default/1/model.lora (1).h5\"\n",
    "# gemma_lm.backbone.load_lora_weights(lora_weights_path)\n",
    "\n",
    "# # 确保加载的权重正确\n",
    "# gemma_lm.summary()\n",
    "\n",
    "# # 使用加载的模型进行推断\n",
    "# template = \"问题:\\n{instruction}\\n\\n回答:\\n{response}\"\n",
    "# prompt = template.format(\n",
    "#     instruction=\"阅读以下唐诗，解释诗歌的含义。正文：春眠不觉晓，处处闻啼鸟。夜来风雨声，花落知多少。\",\n",
    "#     response=\"\",\n",
    "# )\n",
    "# generate_data = gemma_lm.generate(prompt, max_length=256)\n",
    "# match = re.search(r\"Response:\\s*(.*?)(?=(\\nInstruction:|$))\", generate_data, re.DOTALL)\n",
    "# print(match.group(1).strip() if match else str(generate_data))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6375825,
     "sourceId": 10300952,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 3533,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3745.267565,
   "end_time": "2024-12-26T07:42:27.681862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-26T06:40:02.414297",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
