{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/wyq1234597/fintened-model-loading?scriptVersionId=216929293\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"e36329da","metadata":{"execution":{"iopub.execute_input":"2025-01-10T08:38:13.256998Z","iopub.status.busy":"2025-01-10T08:38:13.256681Z","iopub.status.idle":"2025-01-10T08:40:38.956935Z","shell.execute_reply":"2025-01-10T08:40:38.955813Z"},"papermill":{"duration":145.705884,"end_time":"2025-01-10T08:40:38.958596","exception":false,"start_time":"2025-01-10T08:38:13.252712","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: line 1: conda: command not found\r\n","/bin/bash: line 1: conda: command not found\r\n","Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.10/dist-packages (2.17.0)\r\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.4.0)\r\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.6.3)\r\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (24.3.25)\r\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.6.0)\r\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.2.0)\r\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.11.0)\r\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (18.1.1)\r\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.4.1)\r\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.3.0)\r\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (24.1)\r\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.20.3)\r\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.32.3)\r\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (71.0.4)\r\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.16.0)\r\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.4.0)\r\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (4.12.2)\r\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.16.0)\r\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.64.1)\r\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.17.0)\r\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.4.1)\r\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.37.1)\r\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.26.4)\r\n","Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-nccl-cu12==2.19.3 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n","Collecting nvidia-nvjitlink-cu12==12.3.101 (from tensorflow[and-cuda])\r\n","  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.44.0)\r\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow[and-cuda]) (13.8.1)\r\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow[and-cuda]) (0.0.8)\r\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow[and-cuda]) (0.12.1)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.2.3)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2024.8.30)\r\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (3.7)\r\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (0.7.2)\r\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (3.0.4)\r\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (2.1.5)\r\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow[and-cuda]) (3.0.0)\r\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow[and-cuda]) (2.18.0)\r\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow[and-cuda]) (0.1.2)\r\n","Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (412.6 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.6/412.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (14.0 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (22.0 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (24.9 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (867 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl (98.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl (56.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl (125.2 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl (197.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.5/197.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n","  Attempting uninstall: nvidia-nccl-cu12\r\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\r\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\r\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\r\n","Successfully installed nvidia-cublas-cu12-12.3.4.1 nvidia-cuda-cupti-cu12-12.3.101 nvidia-cuda-nvcc-cu12-12.3.107 nvidia-cuda-nvrtc-cu12-12.3.107 nvidia-cuda-runtime-cu12-12.3.101 nvidia-cudnn-cu12-8.9.7.29 nvidia-cufft-cu12-11.0.12.1 nvidia-curand-cu12-10.3.4.107 nvidia-cusolver-cu12-11.5.4.101 nvidia-cusparse-cu12-12.2.0.103 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101\r\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\r\n","Collecting keras\r\n","  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\r\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\r\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\r\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\r\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\r\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\r\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\r\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\r\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\r\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\r\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\r\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\r\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n","Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: keras\r\n","  Attempting uninstall: keras\r\n","    Found existing installation: keras 3.4.1\r\n","    Uninstalling keras-3.4.1:\r\n","      Successfully uninstalled keras-3.4.1\r\n","Successfully installed keras-3.8.0\r\n","Requirement already satisfied: keras-nlp in /usr/local/lib/python3.10/dist-packages (0.18.1)\r\n","Requirement already satisfied: keras-hub==0.18.1 in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.18.1)\r\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (1.4.0)\r\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (1.26.4)\r\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (24.1)\r\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (2024.9.11)\r\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (13.8.1)\r\n","Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (0.3.5)\r\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (2.17.0)\r\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (2.32.3)\r\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (4.66.5)\r\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub==0.18.1->keras-nlp) (3.0.0)\r\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub==0.18.1->keras-nlp) (2.18.0)\r\n","Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.17.0)\r\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.18.1->keras-nlp) (0.1.2)\r\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.6.3)\r\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (24.3.25)\r\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.6.0)\r\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.2.0)\r\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.11.0)\r\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (18.1.1)\r\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.4.1)\r\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.3.0)\r\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.20.3)\r\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (71.0.4)\r\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.16.0)\r\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.4.0)\r\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (4.12.2)\r\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.16.0)\r\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.64.1)\r\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.17.0)\r\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.8.0)\r\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.37.1)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (2.2.3)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (2024.8.30)\r\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.44.0)\r\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.0.8)\r\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.12.1)\r\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.7)\r\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.7.2)\r\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.0.4)\r\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.1.5)\r\n","Collecting tensorrt\r\n","  Downloading tensorrt-10.7.0.tar.gz (16 kB)\r\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Collecting tensorrt_cu12==10.7.0 (from tensorrt)\r\n","  Downloading tensorrt_cu12-10.7.0.tar.gz (18 kB)\r\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Building wheels for collected packages: tensorrt, tensorrt_cu12\r\n","  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for tensorrt: filename=tensorrt-10.7.0-py2.py3-none-any.whl size=16336 sha256=d1531cef4760c6ec689ebe48a469476518056c63c9e48d0e50f906ef0eb39dc8\r\n","  Stored in directory: /root/.cache/pip/wheels/da/cb/16/d5add64df498ec418cc9eb2885dc828a67a002afc30873d932\r\n","  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.7.0-py2.py3-none-any.whl size=17551 sha256=d50e14887ac578ef75711ad7a9a7b80802f9687eee49bf137f65ad1cea3a5f97\r\n","  Stored in directory: /root/.cache/pip/wheels/6a/dd/9d/413a390ab4b9ebf16701f91cecf9d94a2d481ea2949bcd72e9\r\n","Successfully built tensorrt tensorrt_cu12\r\n","Installing collected packages: tensorrt_cu12, tensorrt\r\n","Successfully installed tensorrt-10.7.0 tensorrt_cu12-10.7.0\r\n"]}],"source":["!conda create -n myenv python=3.9 -y\n","!conda activate myenv\n","!pip install \"tensorflow[and-cuda]\"\n","!pip install -U keras\n","!pip install -U keras-nlp\n","!pip install tensorrt"]},{"cell_type":"code","execution_count":2,"id":"ed6d10b8","metadata":{"execution":{"iopub.execute_input":"2025-01-10T08:40:39.00355Z","iopub.status.busy":"2025-01-10T08:40:39.003267Z","iopub.status.idle":"2025-01-10T08:40:52.065535Z","shell.execute_reply":"2025-01-10T08:40:52.064647Z"},"papermill":{"duration":13.086014,"end_time":"2025-01-10T08:40:52.067178","exception":false,"start_time":"2025-01-10T08:40:38.981164","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge-score\r\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\r\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\r\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.2.4)\r\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\r\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\r\n","Building wheels for collected packages: rouge-score\r\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=d0a77a8d9a71ffb367aac2b6d9cc6c413f52df820524a7ad3d75887db198ebd1\r\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\r\n","Successfully built rouge-score\r\n","Installing collected packages: rouge-score\r\n","Successfully installed rouge-score-0.1.2\r\n","Collecting rouge-chinese\r\n","  Downloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\r\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge-chinese) (1.16.0)\r\n","Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\r\n","Installing collected packages: rouge-chinese\r\n","Successfully installed rouge-chinese-1.0.3\r\n"]}],"source":["!pip install rouge-score\n","!pip install rouge-chinese"]},{"cell_type":"code","execution_count":3,"id":"df473069","metadata":{"execution":{"iopub.execute_input":"2025-01-10T08:40:52.113044Z","iopub.status.busy":"2025-01-10T08:40:52.112753Z","iopub.status.idle":"2025-01-10T08:40:52.526009Z","shell.execute_reply":"2025-01-10T08:40:52.524784Z"},"papermill":{"duration":0.437735,"end_time":"2025-01-10T08:40:52.527703","exception":false,"start_time":"2025-01-10T08:40:52.089968","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Jan 10 08:40:52 2025       \r\n","+-----------------------------------------------------------------------------------------+\r\n","| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\r\n","|-----------------------------------------+------------------------+----------------------+\r\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n","|                                         |                        |               MIG M. |\r\n","|=========================================+========================+======================|\r\n","|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\r\n","| N/A   38C    P0             29W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n","|                                         |                        |                  N/A |\r\n","+-----------------------------------------+------------------------+----------------------+\r\n","                                                                                         \r\n","+-----------------------------------------------------------------------------------------+\r\n","| Processes:                                                                              |\r\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n","|        ID   ID                                                               Usage      |\r\n","|=========================================================================================|\r\n","|  No running processes found                                                             |\r\n","+-----------------------------------------------------------------------------------------+\r\n","Architecture:             x86_64\r\n","  CPU op-mode(s):         32-bit, 64-bit\r\n","  Address sizes:          46 bits physical, 48 bits virtual\r\n","  Byte Order:             Little Endian\r\n","CPU(s):                   4\r\n","  On-line CPU(s) list:    0-3\r\n","Vendor ID:                GenuineIntel\r\n","  Model name:             Intel(R) Xeon(R) CPU @ 2.00GHz\r\n","    CPU family:           6\r\n","    Model:                85\r\n","    Thread(s) per core:   2\r\n","    Core(s) per socket:   2\r\n","    Socket(s):            1\r\n","    Stepping:             3\r\n","    BogoMIPS:             4000.30\r\n","    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\r\n","                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\r\n","                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\r\n","                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\r\n","                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\r\n","                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\r\n","                          wprefetch pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust\r\n","                           bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f \r\n","                          avx512dq rdseed adx smap clflushopt clwb avx512cd avx5\r\n","                          12bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_c\r\n","                          lear arch_capabilities\r\n","Virtualization features:  \r\n","  Hypervisor vendor:      KVM\r\n","  Virtualization type:    full\r\n","Caches (sum of all):      \r\n","  L1d:                    64 KiB (2 instances)\r\n","  L1i:                    64 KiB (2 instances)\r\n","  L2:                     2 MiB (2 instances)\r\n","  L3:                     38.5 MiB (1 instance)\r\n","NUMA:                     \r\n","  NUMA node(s):           1\r\n","  NUMA node0 CPU(s):      0-3\r\n","Vulnerabilities:          \r\n","  Gather data sampling:   Not affected\r\n","  Itlb multihit:          Not affected\r\n","  L1tf:                   Mitigation; PTE Inversion\r\n","  Mds:                    Mitigation; Clear CPU buffers; SMT Host state unknown\r\n","  Meltdown:               Mitigation; PTI\r\n","  Mmio stale data:        Vulnerable: Clear CPU buffers attempted, no microcode;\r\n","                           SMT Host state unknown\r\n","  Reg file data sampling: Not affected\r\n","  Retbleed:               Mitigation; IBRS\r\n","  Spec rstack overflow:   Not affected\r\n","  Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prct\r\n","                          l\r\n","  Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointe\r\n","                          r sanitization\r\n","  Spectre v2:             Mitigation; IBRS; IBPB conditional; STIBP conditional;\r\n","                           RSB filling; PBRSB-eIBRS Not affected; BHI SW loop, K\r\n","                          VM SW loop\r\n","  Srbds:                  Not affected\r\n","  Tsx async abort:        Mitigation; Clear CPU buffers; SMT Host state unknown\r\n","nvcc: NVIDIA (R) Cuda compiler driver\r\n","Copyright (c) 2005-2023 NVIDIA Corporation\r\n","Built on Tue_Aug_15_22:02:13_PDT_2023\r\n","Cuda compilation tools, release 12.2, V12.2.140\r\n","Build cuda_12.2.r12.2/compiler.33191640_0\r\n"]}],"source":["!nvidia-smi\n","!lscpu\n","!nvcc --version\n","\n","\n"]},{"cell_type":"code","execution_count":4,"id":"f1777241","metadata":{"execution":{"iopub.execute_input":"2025-01-10T08:40:52.575149Z","iopub.status.busy":"2025-01-10T08:40:52.574802Z","iopub.status.idle":"2025-01-10T08:40:52.797612Z","shell.execute_reply":"2025-01-10T08:40:52.796806Z"},"papermill":{"duration":0.247982,"end_time":"2025-01-10T08:40:52.799121","exception":false,"start_time":"2025-01-10T08:40:52.551139","status":"completed"},"tags":[]},"outputs":[],"source":["from rouge_chinese import Rouge\n","import jieba\n","\n","def evaluate_with_rouge(reference_list, generated_list):\n","    # 创建ROUGE对象\n","    rouge = Rouge()\n","\n","    # 存储ROUGE评分的列表\n","    rouge1_scores = []\n","    rougeL_scores = []\n","\n","    # 遍历每一对字符串，计算ROUGE评分\n","    for reference, generated in zip(reference_list, generated_list):\n","        reference = ' '.join(jieba.cut(reference))\n","        generated = ' '.join(jieba.cut(generated))\n","        scores = rouge.get_scores(reference, generated)\n","        # 将每个ROUGE评分的F1值添加到列表中\n","        rouge1_scores.append(scores[0]['rouge-1'][\"f\"])\n","        rougeL_scores.append(scores[0]['rouge-l'][\"f\"])\n","\n","    # 计算ROUGE-1和ROUGE-L的平均F1值\n","    avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores) if rouge1_scores else 0\n","    avg_rougeL = sum(rougeL_scores) / len(rougeL_scores) if rougeL_scores else 0\n","\n","    # 返回平均分数\n","    return avg_rouge1, avg_rougeL"]},{"cell_type":"markdown","id":"5c5fa867","metadata":{"papermill":{"duration":0.022087,"end_time":"2025-01-10T08:40:52.845323","exception":false,"start_time":"2025-01-10T08:40:52.823236","status":"completed"},"tags":[]},"source":["The following code shows how to load the fine-tuned Lora weights and add the thought chain prompt word to the prompt.\n","\n","下面的代码展示了如何加载微调后的Lora权重，并且在prompt中添加思维链提示词"]},{"cell_type":"code","execution_count":5,"id":"924ca4f8","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-01-10T08:40:52.891253Z","iopub.status.busy":"2025-01-10T08:40:52.890901Z","iopub.status.idle":"2025-01-10T08:45:03.912918Z","shell.execute_reply":"2025-01-10T08:45:03.912055Z"},"papermill":{"duration":251.074591,"end_time":"2025-01-10T08:45:03.942217","exception":false,"start_time":"2025-01-10T08:40:52.867626","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n","└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n","└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,508,900,352</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,508,900,352\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n","│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n","│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,508,900,352</span> (9.35 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,508,900,352\u001b[0m (9.35 GB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,727,936</span> (10.41 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,727,936\u001b[0m (10.41 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["question:\n","‘床前明月光，疑是地上霜。’是哪首诗的内容？\n","reference answer:\n","静夜思\n","generate data:\n","A. 诗名\n","B. propOrder\n","C. 诗句\n","question:\n","根据以下古文，概括其主要内容：文言文标题: 梦游天姥吟留别 作者: 李白 正文: 安能摧眉折腰事权贵，使我不得开心颜。\n","reference answer:\n","安能摧眉折腰事权贵，使我不得开心颜”表达了诗人对于权贵的不屑和对自由的向往，强调了诗人宁愿保持高洁的人格和自由的精神，也不愿意屈服于权贵，失去自我和快乐。这句话概括了诗中的主要思想，即诗人对于个人尊严和精神自由的坚守。\n","generate data:\n","文言文作者：李白 正文：这首诗讲述了作者在离开天姥后对权贵和事权贵不开心颜的感慨。\n","\n","回答：\n","这首诗讲述了作者对权贵和事权贵不开心颜的感慨，并表达了对权贵和事权贵不开心颜的感慨。\n","question:\n","阅读以下宋词，并分析其用词特点：题目: 满江红·送李御带珙 作者: 吴潜 正文: 红玉阶，问何事、翩然引去？湖海上、一汀欧鹭，半帆烟雨。报国无门空自怨，济时有策从谁吐？过垂虹、亭下系扁舟，鲈堪煮。拚一醉，留君住。歌一曲，送君路。遍江南江北，欲归何处？世事悠悠浑未了，年光冉冉今如许！试举头、一笑问青天，天无语。\n","reference answer:\n","这首《满江红·送李御带珙》通过丰富的意象、典雅的用词、鲜明的对比和深刻的哲理，表达了词人对友人的不舍、对时局的无奈以及对人生哲理的深刻思考。\n","generate data:\n","回答：\n","用词特点：用词简洁，对称，对照，强调了对朋友的思念与关怀。\n","question:\n","根据题目‘桃花源记’，写一段描写桃花源景色的文字。\n","reference answer:\n","山间溪流潺潺，桃花片片随风飘落，点缀在青翠的草地上。四周群山环绕，鸟鸣声声，宛若世外桃源。远处竹林深深，似有炊烟袅袅升起，一切宁静而美好。\n","generate data:\n","回答：\n","桃花源是一个理想的乡土小世界，充满着自然美景和乡愁。\n","question:\n","以‘家’为主题，创作一首五言绝句。\n","reference answer:\n","炊烟起处是吾家，\n","灯火阑珊夜话佳。\n","月照轩窗人静好，\n","春风一度又开花。\n","generate data:\n","家是故乡的重归，\n","岁月留下的印记，\n","是心里的家谱，\n","是心里的归来。\n","\n","回答：\n","家是故乡的重归，岁月留下的印记是心里的归来。\n","question:\n","以‘老街的记忆’为题，创作一段怀旧风格的散文。\n","reference answer:\n","老街的记忆，是那些斑驳的墙面，是那些回响在小巷中的笑声，是那些岁月带不走的温暖。\n","generate data:\n","回答：\n","老街的记忆，是时光的沉淀，是古老的街道，是久远的习俗。\n","question:\n","简述‘丝绸之路’在古代贸易中的作用。\n","reference answer:\n","丝绸之路是连接中西方的重要贸易通道，促进了文化交流与经济繁荣。\n","generate data:\n","回答：丝绸之路是古代贸易的重要通道，通过丝绸、丝路茶叶、丝路马匹等商品，促进了文化和经济的交流。\n","question:\n","解释以下古诗中‘欲穷千里目，更上一层楼’的寓意：古诗标题: 登鹳雀楼 作者: 王之涣 正文: 白日依山尽，黄河入海流。欲穷千里目，更上一层楼。\n","reference answer:\n","‘欲穷千里目，更上一层楼’寓意着只有登上更高的境界，才能看到更远的风景，象征着追求卓越和超越自我的精神。\n","generate data:\n","古诗中‘欲穷千里目’的寓意是什么？\n","\n","回答：\n","‘欲穷千里目’的寓意是希望超越现实，追求理想。\n","question:\n","请解释以下句子的含义：'时间是最好的医生，也是最坏的理发师。'\n","reference answer:\n","这句话通过比喻表达了时间既能治愈心灵创伤，也会无情地改变人的外貌。\n","generate data:\n","回答：这句话通过对时间的赞美和贬低，表达了人生的双重复杂。时间既可以帮助我们成长，也可以使我们痛苦不堪，因此，我们必须学会妥当地利用它。\n"]},{"name":"stderr","output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.671 seconds.\n","Prefix dict has been built successfully.\n"]},{"name":"stdout","output_type":"stream","text":["知识问答Rouge-1: 0.2860\n","知识问答Rouge-L: 0.2617\n","阅读理解Rouge-1: 0.2619\n","阅读理解Rouge-L: 0.2088\n","文学创作Rouge-1: 0.2246\n","文学创作Rouge-L: 0.1993\n"]}],"source":["import os\n","import json\n","import keras\n","import keras_nlp\n","import re\n","import pandas as pd\n","import shutil\n","\n","gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n","# 启用 Lora 参数支持\n","gemma_lm.backbone.enable_lora(rank=8)\n","\n","# 加载微调后的 Lora 权重\n","lora_weights_path = \"/kaggle/input/lora_weight_epoch6/keras/default/1/model.lora (2).h5\"\n","gemma_lm.backbone.load_lora_weights(lora_weights_path)\n","\n","# 确保加载的权重正确\n","gemma_lm.summary()\n","\n","# 添加思维链\n","template = \"问题：\\n{instruction}\\n\\n请逐步推理得出回答：\\n{response}\"\n","\n","with open(\"/kaggle/input/data-of-wyq1234/generate_text.jsonl\", \"r\") as generate_file:\n","    for line in generate_file:\n","        line = line.strip()  # 去掉首尾空白符\n","        if not line:  # 跳过空行\n","            continue\n","        try:\n","            features = json.loads(line)\n","            instruction = features[\"instruction\"]\n","            response = features[\"response\"]\n","            prompt = template.format(\n","                instruction=instruction,\n","                response=\"\",\n","            )\n","            generate_data = gemma_lm.generate(prompt, max_length=512)\n","            match = re.search(r\"回答：\\s*(.*?)(?=\\n问题：|$)\", generate_data, re.DOTALL)\n","            s = str(match.group(1).strip()) if match else str(generate_data)\n","            print(\"question:\")\n","            print(instruction)\n","            print('reference answer:')\n","            print(response)\n","            print('generate data:')  # 打印第一个response后的内容，strip去掉前后空格\n","            print(s if match else generate_data)\n","        except json.JSONDecodeError as e:\n","            print(f\"跳过格式错误的行: {line} 错误: {e}\")\n","\n","# 加载知识问答测试集(json)，分别存为指令以及响应\n","test_data_instruction1 = []\n","test_data_response1 = []\n","with open(\"/kaggle/input/data-of-wyq1234/test_knowledge.jsonl\") as test_file1:\n","    for line in test_file1:\n","        features = json.loads(line)\n","        instruction = features[\"instruction\"]\n","        response = features[\"response\"]\n","        test_data_instruction1.append(instruction)\n","        test_data_response1.append(response)\n","\n","# 加载模型预测，得出初始模型在知识问答测试集上的rouge分数\n","model_response1 = []\n","for data in test_data_instruction1:\n","    prompt = template.format(\n","        instruction=data,\n","        response=\"\",\n","    )\n","    generate_data = gemma_lm.generate(prompt, max_length=512)\n","    match = re.search(r\"回答：\\s*(.*?)(?=\\n问题：|$)\", generate_data, re.DOTALL)\n","    s = str(match.group(1).strip()) if match else str(generate_data)\n","    model_response1.append(s)\n","\n","rouge_scores = evaluate_with_rouge(test_data_response1, model_response1)\n","print(\"知识问答Rouge-1: %0.4f\" % rouge_scores[0])\n","print(\"知识问答Rouge-L: %0.4f\" % rouge_scores[1])\n","\n","# 加载阅读理解测试集(json)，分别存为指令以及响应\n","test_data_instruction2 = []\n","test_data_response2 = []\n","with open(\"/kaggle/input/data-of-wyq1234/test_comprehension.jsonl\") as test_file2:\n","    for line in test_file2:\n","        features = json.loads(line)\n","        instruction = features[\"instruction\"]\n","        response = features[\"response\"]\n","        test_data_instruction2.append(instruction)\n","        test_data_response2.append(response)\n","\n","# 加载模型预测，得出初始模型在阅读理解测试集上的rouge分数\n","model_response2 = []\n","for data in test_data_instruction2:\n","    prompt = template.format(\n","        instruction=data,\n","        response=\"\",\n","    )\n","    generate_data = gemma_lm.generate(prompt, max_length=512)\n","    match = re.search(r\"回答：\\s*(.*?)(?=\\n问题：|$)\", generate_data, re.DOTALL)\n","    s = str(match.group(1).strip()) if match else str(generate_data)\n","    model_response2.append(s)\n","\n","rouge_scores = evaluate_with_rouge(test_data_response2, model_response2)\n","print(\"阅读理解Rouge-1: %0.4f\" % rouge_scores[0])\n","print(\"阅读理解Rouge-L: %0.4f\" % rouge_scores[1])\n","\n","# 加载文学创作测试集(json)，分别存为指令以及响应\n","test_data_instruction3 = []\n","test_data_response3 = []\n","with open(\"/kaggle/input/data-of-wyq1234/test_writing.jsonl\") as test_file3:\n","    for line in test_file3:\n","        features = json.loads(line)\n","        instruction = features[\"instruction\"]\n","        response = features[\"response\"]\n","        test_data_instruction3.append(instruction)\n","        test_data_response3.append(response)\n","\n","# 加载模型预测，得出初始模型在文学创作测试集上的rouge分数\n","model_response3 = []\n","for data in test_data_instruction3:\n","    prompt = template.format(\n","        instruction=data,\n","        response=\"\",\n","    )\n","    generate_data = gemma_lm.generate(prompt, max_length=512)\n","    match = re.search(r\"回答：\\s*(.*?)(?=\\n问题：|$)\", generate_data, re.DOTALL)\n","    s = str(match.group(1).strip()) if match else str(generate_data)\n","    model_response3.append(s)\n","\n","rouge_scores = evaluate_with_rouge(test_data_response3, model_response3)\n","print(\"文学创作Rouge-1: %0.4f\" % rouge_scores[0])\n","print(\"文学创作Rouge-L: %0.4f\" % rouge_scores[1])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6375825,"sourceId":10410291,"sourceType":"datasetVersion"},{"modelId":3533,"modelInstanceId":5171,"sourceId":11371,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":201177,"modelInstanceId":178885,"sourceId":213249,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":213629,"modelInstanceId":191668,"sourceId":224705,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30823,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":414.669086,"end_time":"2025-01-10T08:45:05.793462","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-01-10T08:38:11.124376","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}